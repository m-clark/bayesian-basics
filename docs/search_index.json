[["index.html", "Bayesian Basics", " Bayesian Basics Michael Clark m-clark.github.io "],["preface.html", "Preface Prerequisites Going Further Note About the Author", " Preface The following serves as a practical and applied introduction to Bayesian estimation methods for the uninitiated. The goal is to provide just enough information in a brief format to allow one to feel comfortable exploring Bayesian data analysis for themselves, assuming they have the requisite context to begin with. The idea is to cover a similar amount of material as one would in part of a standard statistics sequence in various applied disciplines where statistics is being introduced in general. After a conceptual introduction, a fully visible by-hand example is provided using the binomial distribution. After that, the document proceeds to introduce fully Bayesian analysis with the standard linear regression model, as that is the basis for most applied statistics courses and is assumed to be most familiar to the reader. Model diagnostics, model enhancements, and additional modeling issues are then explored. Supplemental content in the appendix provides more technical detail if desired, and includes a maximum likelihood refresher, an overview of programming options in Bayesian analysis, the same regression model using BUGS and JAGS, and ‘by-hand’ code for the model using the Metropolis-Hastings and Hamiltonian Monte Carlo algorithms. Prerequisites Prerequisites include a basic statistical exposure such as what would be covered in a typical (probably graduate) applied science statistics course. At least some familiarity with R is necessary to follow the code, but that itself is not necessary, and one may go through any number of introductions on the web to acquire enough knowledge in that respect. However, note that for the examples here, at least part of the code will employ some Bayesian-specific programming language (e.g. Stan primarily, BUGS and JAGS in the appendix). No attempt is made to teach those languages though, as it would be difficult to do so efficiently in this more conceptually oriented setting. As such, it is suggested that one follow the code as best they can, and investigate the respective manuals, relevant texts, etc. further on their own. Between the text and comments within the code it is hoped that what the code is accomplishing will be fairly clear. This document relies heavily on Gelman et al. (2013), which I highly recommend, if one is ready for it. Other sources used, or particularly pertinent to the material for this document, can be found in the references section at the end. Some are more introductory, and which might be more suitable depending on the context you bring. Color coding: emphasis package function object/class link Going Further More recently, I offered a two-part practical guide to Bayesian analysis, which I would suggest would be your next step to quickly getting started with models and easy to use tools. I also have a set of old workshop notes that can serve as an overview of Stan and Stan-related packages here and here. There may be additional information and/or exercises that could still be of use. Beyond my own stuff, there are plenty of opportunities to learn Bayesian analysis in the R world, so don’t be afraid to just use something you find that you like. Note This document focuses more on concepts and teaching the Bayesian approach to modeling, while using Stan more as a practical vehicle. However, I do want to say something about the development of Stan and the document itself. Since this document was first put together in Summer of 2014, Stan and associated packages have undergone vast and continued development, and tools for publishing documents with R have as well. Packages such as rstanarm and brms didn’t exist then, but now make even some fairly complicated models easy to pull off with just a line or two of standard R code, and without ever having to use the Stan language directly. Further, newer visualization tools such as bayesplot, tidybayes, and shinystan make model exploration even easier than before. While the document has been updated periodically and so reflects some of these developments, it still leans on conducting analysis more explicitly so that things are not so much of a black box. However, it’s worth noting that the example regression model within and associated diagnostics and visuals would now only take a few lines of R code rather than Stan. In short, the combination of R and Stan make Bayesian analysis easier than ever before. Once armed with the basic concepts, you should feel able to dive in as easily as you would with any other R modeling tool. About the Author I’ve done statistical consulting, conducted workshops, and engaged in scientific research at three universities- University of North Texas, Notre Dame, and the University of Michigan. I am currently a data scientist at Strong Analytics, where I continue to explore and analyze data in all sorts of ways. Writing documents like this helped me learn the techniques I was interested in, and I hope they help you as well! If you have any questions, feel free to reach out. References "],["intro.html", "Introduction Bayesian Probability", " Introduction Bayesian analysis is now fairly common in applied work. It is no longer a surprising thing to see it utilized in non-statistical journals, though it is still fresh enough that many researchers feel they have to put ‘Bayesian’ in the title of their papers when they implement it. However, to be clear, one doesn’t conduct a Bayesian analysis per se. A Bayesian logistic regression is still just logistic regression. The Bayesian part comes into play with the perspective on probability that one uses to interpret the results, and in how the estimates are arrived at. The Bayesian approach itself is very old at this point. Bayes and Laplace started the whole shebang in the 18th and 19th centuries1, and even the modern implementation of it has its foundations in the 30s, 40s and 50s of last century2. So while it may still seem somewhat newer relative to more common techniques, much of the groundwork has long since been hashed out, and there is no more need to justify a Bayesian analysis any more than there is to use the standard maximum likelihood or other approach3. While there are perhaps many reasons why the Bayesian approach to analysis did not catch on until relatively recently, perhaps the biggest is simply computational power. Bayesian analysis requires an iterative and time-consuming approach that simply wasn’t viable for most applied researchers until modern computing. But nowadays, one can conduct such analysis even on their laptop very easily. The Bayesian approach to data analysis requires a different way of thinking about things, but its implementation can be seen as an extension of traditional approaches. In fact, as we will see later, it incorporates the very likelihood one uses in standard statistical techniques. The key difference regards the notion of probability, which, while different than Fisherian or frequentist statistics, is actually more akin to how the average Joe thinks about probability. Furthermore, p-values and intervals will have the interpretation that many applied researchers incorrectly think their current methods provide. On top of this, one gets a very flexible toolbox that can handle many complex analyses. In short, the reason to engage in Bayesian analysis is that it has a lot to offer and can potentially handle whatever you throw at it. As we will see shortly, one must also get used to thinking about distributions rather than fixed points. With Bayesian analysis, we are not so much as making guesses about specific values as in the traditional setting, but more so trying to understand the limits of our knowledge and getting a healthy sense of the uncertainty of those guesses. Bayesian Probability This section will probably be about as formal as this document gets, and will be very minimal even then. The focus still will be on the conceptual understanding though, and subsequently illustrated with a by-hand example in the next section. Conditional probability &amp; Bayes theorem Bayes theorem is illustrated in terms of probability as follows: \\[p(\\mathcal{A}|\\mathcal{B}) = \\frac{p(\\mathcal{B}|\\mathcal{A})p(\\mathcal{A})}{p(\\mathcal{B})}\\] In short, we are attempting to ascertain the conditional probability of \\(\\mathcal{A}\\) given \\(\\mathcal{B}\\) based on the conditional probability of \\(\\mathcal{B}\\) given \\(\\mathcal{A}\\) and the respective probabilities of \\(\\mathcal{A}\\) and \\(\\mathcal{B}\\). This is perhaps not altogether enlightening in and of itself, so we will frame it in other ways, and for the upcoming depictions we will ignore the denominator4. \\[p(hypothesis|data) \\propto p(data|hypothesis)p(hypothesis)\\] In the above formulation5, we are trying to obtain the probability of a hypothesis given the evidence at hand (data) and our initial (prior) beliefs regarding that hypothesis. Here we are already able to see at least one key difference between Bayesian and classical statistics. The Bayesian approach provides a probability of the hypothesis given the data, which is something very desirable from a scientific perspective. Here is yet another way to consider this: \\[posterior \\propto likelihood * prior\\] For this depiction, let us consider a standard regression coefficient \\(b\\)6. Here we have a prior belief about \\(b\\) expressed as a probability distribution. As a preliminary example, we will assume that perhaps the distribution is normal, and is centered on some value \\(\\mu_b\\), and with some variance \\(\\sigma_b^2\\). The likelihood here is the exact same one used in classical statistics- if \\(y\\) is our variable of interest, then the likelihood is \\(p(y|b)\\) as in the standard regression approach using maximum likelihood estimation. What we end up with in the Bayesian context however is not a specific value of \\(b\\) that would make the data most likely, but a probability distribution for \\(b\\) that serves as a weighted combination of the likelihood and prior. Given that posterior distribution for \\(b\\), we can then get the mean, median, 95% credible interval7, and a whole host of other statistics that might be of interest to us. To summarize conceptually, we have some belief about the state of the world, expressed as a mathematical model (such as the linear model used in regression). The Bayesian approach provides an updated belief as a weighted combination of prior beliefs regarding that state, and the currently available evidence. In addition, there is the possibility of the current evidence overwhelming prior beliefs, or prior beliefs remaining largely intact in the face of scant evidence. \\[\\text{updated belief} = \\text{current evidence} * \\text{prior belief or evidence}\\] We will make these concepts more concrete in the next section. Bayes theorem possibly predates Bayes himself by some accounts.↩︎ Jeffreys, Metropolis etc.↩︎ Though some might suggest that the typical practice of hypothesis testing that comes with standard methods would need more.↩︎ The denominator reflects the sum of the numerator for all values \\(\\mathcal{A}\\) might take on. For example: \\[p(\\mathcal{A_i}|\\mathcal{B}) = \\frac{p(\\mathcal{B}|\\mathcal{A_i})p(\\mathcal{A_i})}{p(\\mathcal{B}|\\mathcal{A_i})p(\\mathcal{A_i}) + \\dots + p(\\mathcal{B}|\\mathcal{A_n})p(\\mathcal{A_n})}\\]↩︎ The \\(\\propto\\) means ‘proportional to.’↩︎ If we think of y as our outcome and \\(\\Theta\\) as our set of coefficients that include all the regression coefficients \\(b\\) and \\(\\sigma^2\\) variance, i.e. all parameters we need to estimate for the model: \\[p(\\mathcal{\\Theta}|\\mathcal{y}) = \\frac{p(\\mathcal{y}|\\mathcal{\\Theta})p(\\mathcal{\\Theta})}{p(\\mathcal{y})}\\]↩︎ More on this later.↩︎ "],["example.html", "A Hands-on Example Prior, likelihood, &amp; posterior distributions Prior Likelihood Posterior Posterior predictive", " A Hands-on Example Prior, likelihood, &amp; posterior distributions The following is an attempt to provide a small example to show the connection between the prior distribution, likelihood, and posterior distribution. Let’s say we want to estimate the probability that a soccer/football player8 will score a penalty kick in a shootout. We will employ the binomial distribution to model this. Our goal is to estimate a parameter \\(\\theta\\), the probability that the random knucklehead from your favorite football team will score the penalty in an overtime shootout. Let’s say that for this match it takes 10 shots per team before the game is decided. In R, we can represent the following data for your team as follows, as well as set up some other things for later. shots = c(&#39;goal&#39;,&#39;goal&#39;,&#39;goal&#39;,&#39;miss&#39;,&#39;miss&#39;, &#39;goal&#39;,&#39;goal&#39;,&#39;miss&#39;,&#39;goal&#39;,&#39;goal&#39;) # convert to numeric, arbitrarily picking goal=1, miss=0 shotsNum = as.numeric(shots == &#39;goal&#39;) N = length(shots) # sample size nGoal = sum(shots == &#39;goal&#39;) # number of shots made nMiss = sum(shots == &#39;miss&#39;) # number of those miss Recall the binomial distribution, where we specify the number of trials for a particular observation, and the probability of an event’s occurrence. Let’s look at the distribution for a couple values for \\(\\theta\\) equal to .5 and .85, and \\(N = 10\\) observations. We will repeat this 1000 times. x1 = rbinom(1000, size = 10, p = .5) x2 = rbinom(1000, size = 10, p = .85) mean(x1); hist(x1) [1] 5.043 mean(x2); hist(x2) [1] 8.569 Though I invite you to inspect them, the histograms are not shown, but we can see above that the means are roughly around \\(N*p\\) as we expect with the binomial. Prior For our current situation, we don’t know \\(\\theta\\) and are trying to estimate it. We will start by supplying some possible values. To keep things simple, we’ll only consider 10 values that fall between 0 and 1. theta = seq(from = 1 / (N + 1), to = N / (N + 1), length = 10) theta [1] 0.09090909 0.18181818 0.27272727 0.36363636 0.45454545 0.54545455 0.63636364 0.72727273 0.81818182 0.90909091 For the Bayesian approach we must choose a prior distribution representing our initial beliefs about the estimates we might potentially consider. I provide three possibilities, and note that any one of them would work just fine for this situation. We’ll go with a triangular distribution, which will put most of the weight toward values around \\(.5\\). While we will talk more about this later, I will go ahead and mention now that this is where some people have specifically taken issue with Bayesian estimation in the past, because this part of the process is too subjective for their tastes. Setting aside the fact that subjectivity is an inherent part of the scientific process, and that ignoring prior information (if explicitly available from prior research) would be blatantly unscientific, the main point to make here is that this choice is not an arbitrary one. There are many distributions we might work with, but some will be better for us than others. Again, we’ll revisit this topic later. While we will only work with one prior, I provide others you can play with9. ### prior distribution # triangular as in Kruschke text example pTheta = pmin(theta, 1 - theta) # uniform # pTheta = dunif(theta) # beta prior with mean = .5 # pTheta = dbeta(theta, 10, 10) # Normalize so that values sum to 1 pTheta = pTheta / sum(pTheta) So, given some estimate of \\(\\theta\\), we have a probability of that value based on our chosen prior. Likelihood Next we will compute the likelihood of the data given some value of \\(\\theta\\). Generally, the likelihood for some target variable \\(y\\), with observed values \\(i \\dots n\\), given some (set of) parameter(s) \\(\\theta\\), can be expressed as follows: \\[p(y|\\theta) = \\prod_{i}^{n} p(y_i|\\theta)\\] Specifically, the likelihood function for the binomial can be expressed as: \\[p(y|\\theta) = {N \\choose k}\\, \\theta^k\\, (1-\\theta)^{N-k}\\] where \\(N\\) is the total number of possible times in which the event of interest could occur, and \\(k\\) number of times the event of interest occurs. Our maximum likelihood estimate in this simple setting would simply be the proportion of events witnessed out of the total number of samples10. We’ll use the formula presented above. Technically, the first term is not required, but it serves to normalize the likelihood as we did with the prior11. pDataGivenTheta = choose(N, nGoal) * theta^nGoal * (1 - theta)^nMiss Posterior Given the prior and likelihood, we can now compute the posterior distribution via Bayes theorem. The only thing left to calculate is the denominator from Bayes theorem, then plug in the rest. pData = sum(pDataGivenTheta * pTheta) # marginal probability of the data pThetaGivenData = pDataGivenTheta*pTheta / pData # Bayes theorem Now let’s examine what all we’ve got. theta prior likelihood posterior 0.091 0.033 0.000 0.000 0.182 0.067 0.000 0.000 0.273 0.100 0.005 0.004 0.364 0.133 0.026 0.030 0.455 0.167 0.078 0.112 0.545 0.167 0.162 0.232 0.636 0.133 0.244 0.280 0.727 0.100 0.262 0.226 0.818 0.067 0.177 0.102 0.909 0.033 0.046 0.013 Starting with the prior column, we can see that with the triangular distribution, we’ve given most of our prior probability to the middle values with probability tapering off somewhat slowly towards either extreme. The likelihood, on the other hand, suggests the data is most likely for \\(\\theta\\) values .64-.73, though we know the specific maximum likelihood estimate for \\(\\theta\\) is the proportion for the sample, or 0.7. Our posterior estimate will therefore fall somewhere between the prior and likelihood estimates, and we can see it has shifted the bulk of the probability slightly away from the most likely values suggested by the prior distribution, and towards a \\(\\theta\\) value suggested by the data of 0.7. Let’s go ahead and see what the mean12 is: posteriorMean = sum(pThetaGivenData * theta) posteriorMean [1] 0.6275941 So, we start with a prior centered on a value of \\(\\theta=.5\\), add data whose ML estimate is \\(\\theta=.7\\), and our posterior distribution suggests we end up somewhere in between. We can perhaps understand this further via the following visualizations. In each of these the prior is represented by the blue density, the likelihood by the red, and the posterior by purple. This first is based on a different prior than just used in our example, and instead employs the beta distribution noted among the possibilities in the code above. The beta distribution is highly flexible, and with shape parameters \\(\\mathcal{A}\\) and \\(\\mathcal{B}\\) set to 10 and 10 we get a symmetric distribution centered on \\(\\theta = .5\\). This would actually be a somewhat stronger prior than we might normally want to use, but serves to illustrate a point. The mean of the beta is \\(\\frac{\\mathcal{A}}{\\mathcal{A}+\\mathcal{B}}\\), and thus has a nice interpretation as a prior based on data with sample size equal to \\(\\mathcal{A}+\\mathcal{B}\\). The posterior distribution that results would have a mean somewhere between the maximum likelihood value and that of the prior. With the stronger prior, the posterior is pulled closer to it. The second utilizes a more diffuse prior of \\(\\beta(2,2)\\)13. The result of using the vague prior is that the likelihood gets more weight with regard to the posterior. In fact, if we used a uniform distribution, we would essentially be doing the equivalent of maximum likelihood estimation. In that sense, many of the commonly used methods that implement maximum likelihood can be seen as a special case of a Bayesian approach. The third graph employs the initial \\(\\beta(10,10)\\) prior again, but this time we add more observations to the data. This serves to give more weight to the likelihood, which is what we want. As scientists, we’d want the evidence, i.e. data, to eventually outweigh our prior beliefs about the state of things the more we have of it. For an interactive demonstration of the above, see this. Posterior predictive At this point it is hoped you have a better understanding of the process of Bayesian estimation. Conceptually, one starts with prior beliefs about the state of the world and adds evidence to one’s understanding, ultimately coming to a conclusion that serves as a combination of evidence and prior belief. More concretely, we have a prior distribution regarding parameters, a distribution regarding the data given those parameters, and finally a posterior distribution that is the weighted combination of the two. However, there is yet another distribution of interest to us- the posterior predictive distribution. Stated simply, once we have the posterior distribution for \\(\\theta\\), we can then feed (possibly new or unobserved) data into the data generating process, and get distributions for \\(\\tilde{y}\\)14. Where \\(\\tilde{y}\\) can regard any potential observation, we can distinguish it from the case where we use the current data to produce \\(y^{\\textrm{Rep}}\\), i.e. a replicate of \\(y\\). For example, if a regression model had predictor variables \\(X\\), the predictor variables are identical for producing \\(y^{\\textrm{Rep}}\\) as they were in modeling \\(y\\). However, \\(\\tilde{y}\\) might be based on any values \\(\\tilde{X}\\) that might be feasible or interesting, whether actually observed in the data or not. Since \\(y^{\\textrm{Rep}}\\) is an attempt to replicate the observed data based on the parameters \\(\\theta\\), we can compare our simulated data to the observed data to see how well they match. We can implement the simulation process with the data and model at hand, given a sample of values of \\(\\theta\\) drawn from the posterior. I provide the results of such a process with the following graph. Each bar graph of frequencies represents a replication of the 10 shots taken, i.e. \\(y^{\\textrm{Rep}}\\), given an estimate of \\(\\theta\\) from the posterior distribution (16 total). These are plausible sets of 10 makes and misses, given \\(\\theta\\). With an understanding of the key elements of Bayesian inference in hand, we can proceed to the still familiar but more complex and interesting setting of a regression model. Don’t even start, it’s always been both ‘football’ and ‘soccer.’↩︎ Choose the prior that makes most sense to you. If I were thinking logically, I might choose a prior that reflects that all advantage is to a person that spends their entire life kicking a ball, rather than the person who is required by the rules to stand still. If the penalty taker can simply kick to the upper right or left of the goal, even with only moderate pace, they could point it out like Babe Ruth every time, and simple physics, i.e. that the goalie can never reach the ball given that he has to start in the middle, would mean they score 95% of the time under perfect conditions. We might revise it downward to account for unspecified things, e.g. how tired they are, weather, etc. A prior based on a beta distribution beta(9,1), with a mean of .90, would perhaps be about right. Of course, the data would eventually suggest something much lower, perhaps because soccer players aren’t that bright and don’t listen to their team statistician, or perhaps the games are rigged, but it’s chalked up to drama and mind games because that’s what the fans want to believe (and, more importantly, will pay for). I’ll let you decide that binomial outcome.↩︎ See for yourself in the binomial likelihood section in the appendix.↩︎ Note that if we had covariates as in a regression model, we would have different estimates of theta for each observation, and thus would calculate each observation’s likelihood and then take their product or sum their log values, see the Maximum Likelihhood Review for further details). Even here, if you turn this into binary logistic regression with 10 outcomes of goal scored vs. not, the ‘intercept only’ model would be identical to our results here.↩︎ The expected value for a continuous parameter is \\(\\operatorname{E}[X] = \\int_{-\\infty}^\\infty xp(x)\\mathrm{d}x\\), and for a discrete parameter \\(\\operatorname{E}[X] = \\sum_{i=1}^\\infty x_i\\, p_i\\), i.e. a weighted sum of the possible values times their respective probability of occurrence.↩︎ \\(\\beta(1,1)\\) is a uniform distribution.↩︎ Mathematically represented as: \\(p(\\tilde{y}|y) = \\int p(\\tilde{y}|\\theta)p(\\theta|y)\\mathrm{d}\\theta\\) We can get a sense of the structure of this process via the following table, taken from Gelman: ↩︎ "],["models.html", "Regression Models Example: Linear Regression Model", " Regression Models Now armed with a conceptual understanding of the Bayesian approach, we will actually investigate a regression model using it. To keep things simple, we start with a standard linear model for regression. Later, we will show how easy it can be to add changes to the sampling distribution or priors for alternative modeling techniques. But before getting too far, you should peruse the Modeling Languages section of the appendix to get a sense of some of the programming approaches available. We will be using the programming language Stan via R and the associated R package rstan. If you prefer to keep things conceptual rather than worry about the code, you can read through the following data description and then skip to running the model15. Example: Linear Regression Model In the following we will have some initial data set up and also run the model using the standard lm function for later comparison. I choose simulated data so that not only should you know what to expect from the model, it can easily be modified to enable further understanding. I will also use some matrix operations, and if these techniques are unfamiliar to you, you’ll perhaps want to do some refreshing or learning on your own beforehand. Setup First we need to create the data we’ll use here and for most of the other examples in this document. I use simulated data so that there is no ambiguity about what to expect. # set seed for replicability set.seed(8675309) # create a N x k matrix of covariates N = 250 K = 3 covariates = replicate(K, rnorm(n = N)) colnames(covariates) = c(&#39;X1&#39;, &#39;X2&#39;, &#39;X3&#39;) # create the model matrix with intercept X = cbind(Intercept = 1, covariates) # create a normally distributed variable that is a function of the covariates coefs = c(5, .2, -1.5, .9) mu = X %*% coefs sigma = 2 y = rnorm(N, mu, sigma) # same as # y = 5 + .2*X1 - 1.5*X2 + .9*X3 + rnorm(N, mean = 0, sd = 2) # Run lm for later comparison; but go ahead and examine now if desired modlm = lm(y ~ ., data = data.frame(X[, -1])) # summary(modlm) Just to make sure we’re on the same page, at this point we have three covariates, and a \\(y\\) that is a normally distributed, linear function of them, and with standard deviation equal to 2. The population values for the coefficients including the intercept are 5, 0.2, -1.5, and 0.9, though with the noise sigma added, the actual estimated values for the sample are slightly different. Now we are ready to set up an R list object of the data for input into Stan, as well as the corresponding Stan code to model this data. I will show all the Stan code, which is implemented in R via a single character string, and then provide some detail on each corresponding model block. However, the goal here isn’t to focus on tools as much as it is to focus on concepts16. The data list for Stan should include any matrix, vector, or value that might be used in the Stan code. For example, along with the data one can include things like sample size, group indicators (e.g. for mixed models) and so forth. Here we can get by with just the sample size (N), the number of columns in the model matrix (K), the target variable (y) and the model matrix itself (X). # Create the data list object for Stan input dat = list( N = N, K = ncol(X), y = y, X = X ) Next comes the Stan code. In something like rjags, you would call a separate text file with the code, and one can do the same with rstan17, but for our purposes, we’ll display it within the R code. The first thing to note then is the model code. Next, Stan has programming blocks that have to be called in order. I will have all of the blocks in the code to note their order and discuss each in turn, even though we won’t use them all. Anything following a //, or between \\* \\*, are comments pertaining to the code. Assignments in Stan are =, while distributions are specified with a \\(\\sim\\), e.g. y ~ normal(0, 1) means y is normally distributed with mean 0 and standard deviation of 1. The primary goal here is to get to the results and beyond, but one should examine the Stan manual for details about the code. In addition, to install rstan one will need to do so via CRAN or GitHub (quickstart guide). It does not require a separate installation of Stan itself, but it does take a couple steps, and does require a C++ compiler18. Once you have rstan installed it is called like any other R package as will see shortly. # Create the Stan model object using Stan&#39;s syntax stanmodelcode = &quot; data { // Data block int&lt;lower = 1 &gt; N; // Sample size int&lt;lower = 1&gt; K; // Dimension of model matrix matrix[N, K] X; // Model Matrix vector[N] y; // Target variable } /* transformed data { // Transformed data block. Not used presently. } */ parameters { // Parameters block vector[K] beta; // Coefficient vector real&lt;lower = 0&gt; sigma; // Error scale, lower bound at 0 } model { // Model block vector[N] mu; mu = X * beta; // Creation of linear predictor // priors beta ~ normal(0, 10); sigma ~ cauchy(0, 5); // With sigma bounded, this is half-cauchy // likelihood y ~ normal(mu, sigma); } /* generated quantities { // Generated quantities block. Not used presently. } */ &quot; Stan Code The first section is the data block, where we tell Stan the data it should be expecting from the data list. It is useful to put in bounds as a check on the data input, and that is what is being done between the &lt; &gt; (e.g. we should at least have a sample size of 1). The first two variables declared are N and K, both as integers. Next the code declares the model matrix and target vector respectively. As you’ll note here and for the next blocks, we declare the type and dimensions of the variable and then its name. In Stan, everything declared in one block is available to subsequent blocks, but those declared in a block may not be used in earlier blocks. Even within a block, anything declared, such as N and K, can then be used subsequently, as we did to specify dimensions of the model matrix X. For a reference, the following is from an older version of the Stan manual, but I think still helps clarify a bit (see the latest section here), and notes variables of interest and the associated blocks where they would be declared. Variable Kind Declaration Block modeled, unmodeled data data, transformed data modeled parameters, missing data parameters, transformed parameters unmodeled parameters data, transformed data generated quantities transformed data, transformed parameters, generated quantities loop indices loop statement The transformed data block is where you could do such things as log or center variables and similar, i.e. you can create new data based on the input data, or just in general. If you are using R though, it would almost always be easier to do those things in R first and just include them in the data list. You can also declare any unmodeled parameters here, e.g. constants you want fixed at some value. The primary parameters of interest that are to be estimated go in the parameters block. As with the data block, you can only declare these variables, you cannot make any assignments. Here we note the \\(\\beta\\) and \\(\\sigma\\) to be estimated, with a lower bound of zero on the latter. In practice, you might prefer to split out the intercept or other coefficients to be modeled separately if they are on notably different scales. The transformed parameters block is where optional parameters of interest might be included. What might go here is fairly open, but for efficiency’s sake you will typically want to put things only of specific interest that are dependent on the parameters block. These are evaluated along with the parameters, so if the objects are not of special interest you can instead generate them in the model or generated quantities block to save time. The model block is where your priors and likelihood are specified, along with the declaration of any variables necessary. As an example, the linear predictor is included here, as it will go towards the likelihood19. Note that we could have instead put the linear predictor in the transformed parameters section, but this would slow down the process, and again, we’re not so interested in those specific values. I use a normal prior for the coefficients with a zero mean and a very large standard deviation to reflect my notable ignorance here20. For the \\(\\sigma\\) estimate I use a Cauchy distribution21. Many regression examples using BUGS will use an inverse gamma prior, which is perfectly okay for this model, though it would not work so well for other variance parameters. Had we not specified anything for the prior distribution for the parameters, vague, uniform distributions would be the default (discussed more in the Choice of Prior section). The likelihood is specified in a similar manner as one would with R. BUGS style languages would actually use dnorm as in R, though Stan uses normal for the function name. Finally, we get to the generated quantities, which is kind of a fun zone. Anything you want to calculate can go here - predictions on new data, ratios of parameters, how many times a parameter is greater than x, transformations of parameters for reporting purposes, and so forth. We will demonstrate this later. Running the Model Now that we have an idea of what the code is doing, let’s put it to work. Bayesian estimation, like maximum likelihood, starts with initial guesses as starting points and then runs in an iterative fashion, producing simulated draws from the posterior distribution at each step, and then adjusting those draws until finally getting to some target, or stationary distribution. This part is key, and different from classical statistics. We are aiming for a distribution, not a point estimate. The simulation process is referred to as Markov Chain Monte Carlo, or MCMC for short. The specifics of this process are what sets many of the Bayesian programming languages/approaches apart, and something we will cover in more detail in a later section (see Sampling Procedure). In MCMC, all of the simulated draws from the posterior are based on, and correlated with, previous draws22, as the process moves along the path toward a stationary distribution. We will typically allow the process to warm up, or rather get a bit settled down from the initial starting point, which might be way off, and thus the subsequent estimates will also be way off for the first few iterations23. Rest assured, assuming the model and data are otherwise acceptable, the process will get to where it needs to go. However, as a further check, we will run the whole thing multiple times, i.e. have more than one chain. As the chains will start from different places, if multiple chains get to the same place in the end, we can feel more confident about our results. While this process may sound like it might take a long time to complete, for the following you’ll note that it will take much more time for Stan to compile its code to C++ than it will to run the model24, and on my computer each chain only takes less than one-tenth of a second. However, the Bayesian approach used to take a very long time even for a standard regression such as this, and that is perhaps the primary reason why Bayesian analysis only caught on in the last couple decades; we simply didn’t have the machines to do it efficiently. Even now though, for highly complex models and large data sets it can still take a long time to run, though typically not prohibitively so. In the following code, we note the object that contains the Stan model code, the data list, how many iterations we want (2000)25, how long we want the process to run before we start to keep any estimates (warmup = 1000), how many of the post-warmup draws of the posterior we want to keep (thin = 4 means every fourth draw), and the number of chains (chains = 4). In the end, we will have four chains for a total of 100026 draws from the posterior distribution of the parameters. Stan spits out a lot of output to the R console even with verbose = FALSE, and I omit it here, but you will see some initial info about the compiling process, updates as each chain gets through 10% of iterations specified in the iter argument, and finally an estimate of the elapsed time. You may also see informational messages which, unless they are highly repetitive, should not be taken as an error. library(rstan) ### Run the model and examine results fit = stan( model_code = stanmodelcode, data = dat, iter = 2000, warmup = 1000, thin = 4, chains = 4 ) With the model run, we can now examine the results. In the following, we specify the digit precision to display, which parameters we want (not necessary here), and which quantiles of the posterior draws we want, which in this case are the median and those that would produce a 95% interval estimate. # summary print( fit, pars = c(&#39;beta&#39;, &#39;sigma&#39;), digits = 3, prob = c(.025, .5, .975) ) Inference for Stan model: anon_model. 4 chains, each with iter=2000; warmup=1000; thin=4; post-warmup draws per chain=250, total post-warmup draws=1000. mean se_mean sd 2.5% 50% 97.5% n_eff Rhat beta[1] 4.891 0.004 0.123 4.648 4.889 5.142 1142 1.000 beta[2] 0.083 0.004 0.131 -0.163 0.083 0.336 912 1.006 beta[3] -1.473 0.004 0.129 -1.728 -1.475 -1.215 910 0.999 beta[4] 0.819 0.004 0.119 0.583 0.816 1.059 988 0.999 sigma 2.033 0.003 0.090 1.859 2.029 2.211 844 0.998 Samples were drawn using NUTS(diag_e) at Sat Feb 19 11:21:03 2022. For each parameter, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence, Rhat=1). So far so good. The mean estimates reflect the mean of posterior draws for the parameters of interest, and are the typical coefficients reported in standard regression analysis. The 95% probability, or credible intervals, are worth noting, because they are not confidence intervals as you know them. There is no repeated sampling interpretation here27. The probability interval is more intuitive. It means simply that, based on the results of this model, there is a 95% chance the true value will fall between those two points. The other values printed out I will return to in just a moment. Comparing the results to those from R’s lm function, we can see we obtain similar estimates, as they are identical to two decimal places. In fact, had we used uniform priors28, we would be doing essentially the same model as what is being conducted with standard maximum likelihood estimation. Here, we have a decent amount of data for a model that isn’t complex, so we would expect the likelihood to notably outweigh the prior, as we demonstrated previously with our binomial example. summary(modlm)   Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 4.898 0.1284 38.13 3.026e-105 X1 0.08408 0.1296 0.6488 0.5171 X2 -1.469 0.1261 -11.64 3.049e-25 X3 0.8196 0.1207 6.793 8.207e-11 Fitting linear model: y ~ . Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 250 2.021 0.4524 0.4458 But how would we know if our model was working out okay otherwise? There are several standard diagnostics, and we will talk about them in more detail in the next section, but let’s take a look at some presently. In the summary, se_mean is the Monte Carlo error, and is an estimate of the uncertainty contributed by only having a finite number of posterior draws. n_eff is effective sample size given all chains, and essentially accounts for autocorrelation in the chain, i.e. the correlation of the estimates as we go from one draw to the next. It actually doesn’t have to be very large, but if it was small relative to the total number of draws desired, that might be cause for concern. Rhat is a measure of how well chains mix, and goes to 1 as chains are allowed to run for an infinite number of draws. In this case, n_eff and Rhat suggest we have good convergence, but we can also examine this visually with a traceplot. # Visualize stan_trace(fit, pars=c(&#39;beta[4]&#39;)) I only show one parameter above, but one should always look at the traceplots for all parameters. What we are looking for after the warmup period is a “fat hairy caterpillar” or something that might be labeled as “grassy,” and this plot qualifies as such29. One can see that the estimates from each chain find their way from the starting point to a more or less steady state quite rapidly (initial warmup iterations in gray). Furthermore, all chains, each noted by a different color, are mixing well and bouncing around the same conclusion. So the statistical measures and traceplot suggest that we are doing okay. The Stan development crew has made it easy to interactively explore diagnostics via the shinystan package, and one should do so with each model. In addition, there are other diagnostics available in other packages like loo and posterior. So there you have it. Aside from the initial setup with making a data list and producing the language-specific model code, it doesn’t necessarily take much to running a Bayesian regression model relative to standard models30. The main thing perhaps is simply employing a different mindset, and interpreting the results from within that new perspective. For the standard models you are familiar with, it probably won’t take too long to be as comfortable here as you were with those, and now you will have a flexible tool to take you into new realms with deeper understanding. For just a standard regression model I would ultimately suggest using rstanarm or brms, because they would allow you to keep to the usual R approach for modeling, allowing you to more or less jump right in. However, writing Stan code makes it clearer what is being done, so we’ll keep to it for our purposes here. When I first started writing this document, brms didn’t exist, rstanarm was still in its infancy, there was no interactive shinystan etc. I may end up moving the Stan code to the appendix and just using rstanarm in the future, but I think it’s worth knowing what’s actually going on specifically behind the scenes, so will stick to the rstan approach for now.↩︎ Related code for this same model in BUGS and JAGS is provided in the appendix here. I don’t think there is an easy way to learn these programming languages except by diving in and using them yourself with models and data you understand. In general their modeling syntax is not too difficult to translate from Stan and often very similar.↩︎ In your own Stan pursuits, it’s better to have the Stan model as a separate file.↩︎ You can examine this list of compilers, or on Windows simply install Rtools from the R website (recommended). Note that you may already have one incidentally. Try the Stan test in their ‘getting started’ guide before downloading one.↩︎ The position within the model block isn’t crucial. I tend to like to do all the variable declarations at the start, but others might prefer to have them under the likelihood heading at the point they are actually used.↩︎ By setting the prior mean to zero, this will have the effect of shrinking the coefficients toward zero to some extent. In this sense, it is equivalent to penalized regression in the non-Bayesian setting, ridge regression in particular.↩︎ Actually, a half-Cauchy as it is bounded to be positive. This is equivalent to a student t with df=1, and there is some tendency of late to use the student t directly with df=3 for slight gains in performance for some models.↩︎ In a Markov Chain, \\(\\theta_t\\) is independent of previous \\(\\theta_{t-2...t_1}\\), conditional on \\(\\theta_{t-1}\\).↩︎ How far one wants to go down the rabbit hole regarding MCMC is up to the reader. A great many applied researchers do classical statistical analysis without putting much thought into the actual maximum likelihood estimation process, and I suppose one could do so here as well.↩︎ Not usually the case except for simple models with smaller data.↩︎ This is probably overkill for a simple model like this. One probably would be fine with 500 warm-up and 500 iterations for a standard regression.↩︎ \\(\\frac{2000-1000}{4} \\cdot 4 = 1000\\)↩︎ A standard confidence interval implies that if we’d done the study exactly the same over and over, and calculated a confidence interval each time, 95% of them would capture the true value. The one you end up with is just one from that process.↩︎ In Stan code this can be done by not explicitly specifying a prior.↩︎ Like all model diagnostics, we aren’t dealing with an exact science.↩︎ As noted previously, other R packages would allow for regression models to be specified just like you would with the lm and glm functions. See the rstanarm (from the developers of Stan) and brms packages especially.↩︎ "],["diagnostics.html", "Model Exploration Monitoring Convergence Model Criticism Summary", " Model Exploration As with modeling in traditional approaches, it is not enough to simply run a model and go with whatever results are returned without further inspection. One must examine the results to assess model integrity and have more confidence in the results that have been produced31. Monitoring Convergence There are various ways to assess whether or not the model has converged to a target distribution32, but as with more complex models in MLE, there is nothing that can tell you for sure that you’ve hit upon the true solution. As a starting point, Stan or other modeling environments will likely return repeated warnings or errors if something is egregiously wrong, or perhaps take an extraordinarily long time to complete relative to expectations, if it ever finishes at all. Assuming you’ve at least gotten past that point, there is more to be done. Visual Inspection: Traceplot &amp; Densities In the previous model we noted the traceplot for a single parameter, and a visual approach to monitoring convergence is certainly one good method. In general, we look for a plot that shows random scatter around a mean value, and our model results suggest that the chains mixed well and the traceplot looked satisfactory. This above shows an example where things have gone horribly wrong. The chains never converge, nor do they mix with one another. One reason for running multiple chains is that any individual chain might converge toward one target, while another chain might converge elsewhere, and this would still be a problem. Also, you might see otherwise healthy chains get stuck on occasion over the course of the series, which might suggest more model tweaking or a change in the sampler settings is warranted. We can examine the mixed chains and density plots of the posterior with standard functions in the rstan package displayed previously, various functions in the bayesplot package, or interactively via shinyStan package and its launch_shiny function. In the Bayesian approach, increasing amounts of data leads to a posterior distribution of the parameter vector approaching multivariate normality. The following shows a density, trace and autocorrelation plots for one of the regression coefficients using shinyStan. Statistical Measures To go along with visual inspection, we can examine various statistics that might help our determination of convergence or lack thereof. Gelman and Rubin’s potential scale reduction factor, \\(\\hat{R}\\), provides an estimate of convergence based on the variance of an estimated parameter \\(\\theta\\) between chains, and the variance within a chain. It is interpreted as the factor by which the variance in the estimate might be reduced with longer chains. We are looking for a value near 1 (and at the very least less than 1.1), and it will get there as \\(N_{sim} \\rightarrow \\infty\\). In the regression model things are looking good in this respect. term estimate rhat beta[1] 4.889 1.000 beta[2] 0.083 1.006 beta[3] -1.475 0.999 beta[4] 0.816 0.999 sigma 2.029 0.998 The coda package provides other convergence statistics based on Geweke (1992) and Heidelberger and Welch (1983). Along with those statistics, it also has plots for the \\(\\hat{R}\\) and Geweke diagnostics. Autocorrelation As noted previously, each estimate in the MCMC process is serially correlated with the previous estimates by definition. Furthermore, other aspects of the data, model, and estimation settings may contribute to this. Higher serial correlation typically has the effect of requiring more samples in order to get to a stationary distribution. If inspection of the traceplots look more ‘snake-like’ than like a fat hairy caterpillar, this might suggest such a situation, and that more samples are required. We can also look at the autocorrelation plot, in which the chain’s correlation with successive lags of the chain are plotted. The first plot is the autocorrelation plot from our model (starting at lag 1). The correlation is low to begin with and then just bounces around zero after. The next plot shows a case of high serial correlation, where the correlation with the first lag is high and the correlation persists even after longer lags. A longer chain with more thinning could help with this. The effective number of simulation draws is provided as \\(n_{\\textrm{eff}}\\) in the Stan output, and is similarly obtained in BUGS/JAGS. Ideally, we would desire this number to equal the number of posterior draws requested, and in the presence of essentially no autocorrelation the values would be equal. This is not a requirement though, and technically a low number of draws would still be usable. However, a notable discrepancy might suggest there are some issues with the model, or simply that longer chains could be useful. In our current model, all our effective sample sizes are at or near the total number of posterior draws. term estimate ess beta[1] 4.889 1142 beta[2] 0.083 912 beta[3] -1.475 910 beta[4] 0.816 988 sigma 2.029 844 Monte Carlo error is an estimate of the uncertainty contributed by only having a finite number of posterior draws. We’d typically want roughly less than 5% of the posterior standard deviation (reported right next to it in the Stan output), but might as well go for less than 1%. With no autocorrelation it would equal \\(\\sqrt{\\frac{var(\\theta)}{n_{\\textrm{eff}}}}\\)33. and \\(n_{\\textrm{eff}}\\) would equal the number of simulation draws requested. mean se_mean beta[1] 4.891 0.004 beta[2] 0.083 0.004 beta[3] -1.473 0.004 beta[4] 0.819 0.004 sigma 2.033 0.003 Model Criticism Checking the model for suitability is crucial to the analytical process34. Assuming initial diagnostic inspection for convergence has proven satisfactory, we must then see if the model makes sense in its own right. This can be a straightforward process in many respects, and with Bayesian analysis one has a much richer environment in which to do so compared to traditional methods. Sensitivity Analysis Sensitivity analysis entails checks on our model settings to see if changes in them, perhaps even slight ones, result in changes in posterior inferences. This may take the form of comparing models with plausible but different priors, different sampling distributions, or differences in other aspects of the model such as the inclusion or exclusion of explanatory variables. While an exhaustive check is impossible, at least some effort in this area should be made. Predictive Accuracy &amp; Model Comparison A standard way to check for model adequacy is simply to investigate whether the predictions on new data are accurate. In general, the measure of predictive accuracy will be specific to the data problem, and involve posterior simulation of the sort covered in the next section. In addition, while oftentimes new data is hard to come by, assuming one has sufficient data to begin with, one could set aside part of it specifically for this purpose. In this manner one trains and tests the model in much the same fashion as machine learning approaches. In fact, one can incorporate the validation process as an inherent part of the modeling process in the Bayesian context just as you would there. For model comparison of out of sample predictive performance, there are information measures similar to the Akaike information criterion (AIC), that one could use in the Bayesian environment. One not to use is the so-called Bayesian information criterion (or BIC), which is not actually Bayesian nor a measure of predictive accuracy. Some approaches favor the DIC, or deviance information criterion, as part of its summary output, which is a somewhat Bayesian version of the AIC. More recently developed are measures like LOO (leave-one-out criterion) and the WAIC, or Watanabe-AIC35, which are fully Bayesian approaches. Under some conditions, the DIC and WAIC measures are asymptotically equivalent to Bayesian leave-one-out cross validation, as the AIC is under the classical setting. Posterior Predictive Checking: Statistical For an overall assessment of model fit, we can examine how well the model can reproduce the data at hand given the \\(\\theta\\) draws from the posterior. We discussed earlier the posterior predictive distribution for a future observation \\(\\tilde{y}\\)36, and here we’ll dive in to using it explicitly. There are two sources of uncertainty in our regression model, the variance in \\(y\\) not explained by the model (\\(\\sigma^2\\)), and posterior uncertainty in the parameters due to having a finite sample size. As \\(N\\rightarrow\\infty\\), the latter goes to zero, and so we can simulate draws of \\(\\tilde{y} \\sim N(\\tilde{X}\\beta, \\sigma^2I)\\)37. If \\(\\tilde{X}\\) is the model data as in the following, then we will refer to \\(y^{\\textrm{Rep}}\\) instead of \\(\\tilde{y}\\). For our model, this entails extracting the simulated values from the model object, and taking a random draw from the normal distribution based on the \\(\\beta\\) and \\(\\sigma\\) that are drawn to produce our replicated data, \\(y^{\\textrm{Rep}}\\) (see Gelman et al. (2013), Appendix C). In what follows, I write out the process explicitly, but bayesplot, rstanarm, and brms make this straightforward, possibly with a single line of code, the latter packages using bayesplot. In addition, it’s often simpler to create the \\(y^{\\textrm{Rep}}\\) as part of your generated quantities section of the model code if modeling with Stan explicitly. # extract the simulated draws from the posterior and note the number for nsims theta = extract(fit) betas = theta$beta sigmas = theta$sigma nsims = length(theta$sigma) # produce the replications and inspect yRep = sapply(1:nsims, function(s) rnorm(250, X %*% betas[s,], sigmas[s])) str(yRep) num [1:250, 1:1000] 4.44 4.47 1.12 4.3 10.04 ... With the \\(y^{\\textrm{Rep}}\\) in hand we can calculate all manner of statistics that might be of interest38. As a starting point, we can check our minimum value among the replicated data sets versus that observed in the data. min_rep = apply(yRep, 2, min) min_y = min(y) c(mean(min_rep), min_y) [1] -2.831253 -6.056495 prop.table(table(min_rep &gt; min_y)) FALSE TRUE 0.013 0.987 sort(y)[1:5] [1] -6.0564952 -3.2320527 -2.6358579 -2.1649084 -0.8366149 These results suggest we may be having difficulty picking up the lower tail of the target variable, as our average minimum is notably higher than that seen in the data, and almost all our minimums are greater than the observed minimum (\\(p=.99\\)). While in this case where we are dealing with a simulated data set and we know that assuming the normal distribution for our sampling distribution is appropriate, this might otherwise have given us pause for further consideration. A possible solution would be to assume a \\(t\\) distribution for the likelihood, which would have fatter tails and thus possibly be better able to handle extreme values. We’ll show an example of this later. In this case it is just that by chance one of the \\(y\\) values, -6.056, is fairly extreme relative to the others. Also, it is typically difficult to capture extreme values in practice. As a comparison, the model actually captures the 5th, 10th (shown), and 25th quantile values very well. See ppc_stat in bayesplot. In general, we can devise a test statistic, \\(T_{\\textrm{Rep}}\\), and associated p-value to check any particular result of interest based on the simulated data. The p-value in this context is simply the percentage of times the statistic of interest is equal to or more extreme than the statistic, \\(T_y\\), calculated for the original data. Thus p-values near 0 or 1 are indicative of areas where the model is falling short in some fashion. Sometimes \\(T_y\\) may be based on the \\(\\theta\\) parameters being estimated, and thus you’d have a \\(T_y\\) for every posterior draw. In such a case, one might examine the scatterplot of \\(T_{\\textrm{Rep}}\\) vs. \\(T_y\\), or examine a density plot of the difference between the two. In short, this is an area where one can get creative, and the bayesplot package can help with make this fairly easy. However, it must be stressed that we are not trying to accept or reject a model hypothesis as in the frequentist setting- we’re not going to throw a model out because of an extreme p-value in our posterior predictive check. We are merely trying to understand the model’s shortcomings as best we can, and make appropriate adjustments if applicable. It is often the case that the model will still be good enough for practical purposes. Posterior Predictive Checking: Graphical As there are any number of ways to do statistical posterior predictive checks, we have many options for graphical inspection as well. I show a graph of our average fitted values versus the observed data as a starting point. The average is over all posterior draws of \\(\\theta\\). See ppc_scatter_avg in bayesplot. Next, I show density plots for a random sample of 20 of the replicated data sets along with that of the original data (shaded). It looks like we’re doing pretty well here. The subsequent figure displays the density plot for individual predictions for a single value of \\(y\\) from our data. In general, the model captures this particular observation of the data decently. See ppc_dens_overlay in bayesplot. We can also examine residual plots of \\(y - E(y|X,\\theta)\\) as with standard analysis, shown as the final two figures for this section. The first shows such ‘realized’ residuals, so-called as they are based on a posterior draw of \\(\\theta\\) rather than point estimation of the parameters, versus the expected values from the model. The next plot shows the average residual against the average fitted value. No discernible patterns are present, so we may conclude that the model is adequate in this regard39. Summary As with standard approaches, every model should be checked to see whether it holds up under scrutiny. The previous discussion suggests only a few ways one might go about checking whether the model is worthwhile, but this is a very flexible area where one can answer questions beyond model adequacy and well beyond what traditional models can tell us. Not only is this phase of analysis a necessity, one can use it to explore a vast array of potential questions the data presents, and maybe even answer a few. References "],["enhancements.html", "Model Enhancements Generating New Variables of Interest Robust Regression Generalized Linear Model", " Model Enhancements Enhancing and making adjustments to a model can often be straightforward in the Bayesian context, depending on what one wants to accomplish. In other cases, some things may be possible that aren’t readily available with standard approaches in the traditional setting. The following shows a few brief examples to give an idea of the possibilities. Generating New Variables of Interest We have already seen one way to get at new statistics of interest in the predictive model checking section. I next show how to do so as part of the modeling process itself. In Stan, we can accomplish this via the generated quantities section. A typical part of linear regression output is \\(R^2\\), the amount of variance accounted for by the model. To get this in Stan we just have to create the code necessary for the calculations, and place it within the generated quantities section. I only show this part of the model code; everything we had before would remain the same. I show the corresponding lm results from R for comparison. There are a couple of ways to go about this, and I use some of Stan’s matrix operations as one approach. . . . generated quantities { real rss; real totalss; real&lt;lower=0, upper=1&gt; R2; vector[N] mu; mu &lt;- X * beta; rss &lt;- dot_self(y-mu); totalss &lt;- dot_self(y-mean(y)); R2 &lt;- 1 - rss/totalss; } Using the results from the model using lm, we do the same calculations for rss and totalss, and note the result is identical to what you’d see in the summary of the model. rss = crossprod(resid(modlm)) totalss = crossprod(y - mean(y)) rss = rss[1] totalss = totalss[1] # for alignment, remove matrix 1 - rss / totalss [1] 0.4524289 summary(modlm)$r.squared [1] 0.4524289 Now we can run the model with added \\(R^2\\) 40. Note that as before we do not just get a point estimate, but a whole distribution of simulated values for \\(R^2\\). First the results. print( fitRsq, digits = 3, par = c(&#39;beta&#39;, &#39;sigma&#39;, &#39;R2&#39;), prob = c(.025, .5, .975) ) Inference for Stan model: stanmodelcodeRsq. 3 chains, each with iter=12000; warmup=2000; thin=10; post-warmup draws per chain=1000, total post-warmup draws=3000. mean se_mean sd 2.5% 50% 97.5% n_eff Rhat beta[1] 4.895 0.002 0.129 4.639 4.897 5.144 2884 1.000 beta[2] 0.087 0.002 0.131 -0.169 0.086 0.342 2776 1.000 beta[3] -1.466 0.002 0.125 -1.712 -1.469 -1.219 2826 0.999 beta[4] 0.821 0.002 0.123 0.584 0.820 1.063 2987 0.999 sigma 2.028 0.002 0.091 1.858 2.025 2.212 2945 1.000 R2 0.443 0.000 0.006 0.427 0.445 0.451 2932 1.000 Samples were drawn using NUTS(diag_e) at Sat May 24 13:10:08 2014. For each parameter, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence, Rhat=1). The nice thing here is that our \\(R^2\\) incorporates the additional uncertainty in estimating the model parameters, and thus acts like an adjusted \\(R^2\\) 41. The following is the classical regression adjusted \\(R^2\\). summary(modlm)$adj [1] 0.4457512 Furthermore, in the Bayesian context we get an interval estimate and everything else we typically get as with other quantities of interest, and the same would be true for anything else we want to calculate (e.g. predictions). In addition, it would be trivial to calculate something like the actual adjusted \\(R^2\\), the probability that the \\(R^2\\) value is greater than .5, and other things of that nature. Robust Regression If we were concerned that extreme observations exist that our current model is not able to capture well, we could change the sampling distribution to one that had a little more probability in the tails. This is very easy to do in this situation, as we just change likelihood portion of our code to employ say, a t-distribution42. In Stan, the t-distribution has parameters mean and sigma as with the normal distribution, but we also have the added parameter for degrees of freedom. So our code might look like the following: stanmodelcodeT = &quot; . . . model { vector[N] mu; mu &lt;- X * beta; // priors beta ~ normal(0, 10); sigma ~ cauchy(0, 5); // likelihood // y ~ normal(mu, sigma); // previously used normal y ~ student_t(10, mu, sigma) // t with df=10 } &quot; In this case we set the degrees of freedom at 1043, but how would you know in advance what to set it as? It might be better to place a prior (with lower bound of one) for that value, and then estimate it as part of the modeling process. One should note that there are many distributions available in Stan (e.g. others might be useful for skewed data, truncated etc.), and more will be added in the future. Generalized Linear Model Expanding from standard linear model, we can move very easily to generalized linear models, of which the standard regression is a special case. The key components are use of a link function that links the linear predictor to the target variable, and an appropriate sampling distribution for the likelihood. Let’s consider a count model using the Poisson distribution. We can specify the model as follows: \\[y \\sim Pois(\\lambda)\\] \\[g(\\lambda) = X\\beta\\] where \\(g(.)\\) is the link function, the canonical link function for Poisson being the natural logarithm. In Stan, this can be expressed via the inverse link function, where we exponentiate the linear predictor44. Aside from that we simply specify \\(y\\) as distributed Poisson in the same way we used the normal and t-distribution in earlier efforts. stanmodelcodePoisson = &quot; . . . model { vector[N] lambda; vector[N] eta; eta &lt;- X * beta; lambda &lt;- exp(eta) // priors beta ~ normal(0, 10); // likelihood y ~ poisson(lambda) } &quot; And that’s all there is to that45. We just saw that we are not limited to the exponential family distributions of GLM(s), though that covers a lot of ground, and so at this point you have a lot of the tools covered in standard applied statistics course, and a few beyond. With the rstanarm package, R2 is automatically calculated and provided with the stan_lm function. It is also available in rstanarm and brms via the bayes_R2 function.↩︎ See Gelman &amp; Pardoe (2006), Bayesian Measures of Explained Variance.↩︎ Note that with the brms package all one would have to do is change the family argument in the model function.↩︎ Alternatively, we could add a value ‘df’ to the data list and data block.↩︎ You can also forgo the exponentiation and instead use the poisson_log function in your sampling statement (slightly faster too).↩︎ Note that in various modeling scenarios, you might have to loop over the values of \\(y\\), for(n in 1:N) ... to incorporate additional complexity. In general, a vectorized approach as we have done is preferable if it’s possible.↩︎ "],["issues.html", "Issues Debugging Choice of Prior Sampling Procedure Number of draws, thinning, warm-up Model Complexity", " Issues This section highlights some things to think about, as well as questions that would naturally arise for the applied researcher who might now be ready to start in on their first Bayesian analysis. It provides merely a taste regarding some select issues, and at this point one should be consulting Bayesian analysis texts directly. Debugging An essential part of Bayesian analysis is debugging to see if your code and model are doing what it should be doing46, and this especially holds for more complex models. For many models with typical numbers for posterior draws, Bayesian analysis might take several minutes on standard computers or laptops. With big data and/or very complex models, some might take hours or even days. In either case, it is a waste of time to let broken code/models run unnecessarily. The idea with debugging is that, once you think you have everything set up the way you like, run very short attempts to see if A, the code even compiles, and B, whether it runs appropriately. As such, you will only want to set your warm-up and iterations to some small number to begin with, e.g. maybe not even 100 iterations, and maybe no more than two chains47. Sometimes it will be obvious what a problem is, such as a typo resulting in the program not being able to locate the parameter of interest. Other issues may be fairly subtle, for example, when it comes to prior specification. Along with initial short runs, one should consider simpler models first, and perhaps using only a subset of the data. Especially for complex models, it helps to build the model up, debugging and checking for problems along the way. As a not too complicated example, consider a mixed model for logistic regression. One could even start with a standard linear model ignoring the binary nature of the target and random effect structure. Getting a sense of things from that, and just making sure that inputs and other things are in place, one can then supply the inverse logit link and change the sampling distribution to Bernoulli. Now you can think about adding the random effect, other explanatory variables of interest, and any other complexities that had not been included yet. Then you can add something like accuracy or other metrics to your generated quantities block As you identify issues, you fix any problems that arise and tinker with other settings. Once you are satisfied, then try for the big run. Even then, you might spot new issues with a longer chain, so you can rinse and repeat at that point. Stan and other languages like BUGS/JAGS more or less have this capacity built in with model upgrade functions. For example, in Stan you can feed the previous setup of a model in to the main stan function. Use one for your initial runs, then when you’re ready, supply the model object as input to the fit argument, perhaps with adjustments to the Monte Carlo settings. Choice of Prior Selection of prior distributions can be a bit daunting for the new user of applied Bayesian analysis. However, in many cases, and especially for standard models, there are more or less widely adopted choices. Even so, we will discuss the options from a general point of view, and some tips for selection. Noninformative, Weakly Informative, Informative We can begin with noninformative priors, which might also be referred to as vague, flat, reference, objective, or diffuse depending on the context. The idea is to use something that allows for Bayesian inference but puts all the premium on the data, and/or soi-disant objectivity, though the fact that there is still choice here should make clear that these are not entirely noninformative or objective. As we have alluded to elsewhere, if we put a prior uniform distribution on the regression coefficients (and e.g. the log of \\(\\sigma\\)), this would be a noninformative approach that would essentially be akin to maximum likelihood estimation. One might wonder at this point why we wouldn’t just use vague priors all the time and not worry about overly influencing the analysis by the choice of prior. As an example, let’s assume a uniform distribution \\((-\\infty,\\infty)\\) for some parameter \\(\\theta\\). Without bounds, this prior is improper, i.e. the probability distribution does not integrate to 1. While the posterior distribution might be proper, it also might not be, and it is left the researcher to determine this. One also has to choose a suitable range, something which may not be easy to ascertain. In addition, the distribution may not be uniform on some transformation of the parameter, say \\(\\theta^2\\). A Jeffreys’ prior could be used to overcome this particular issue, but is more difficult for multiparameter settings. In general, there are several issues with using a noninformative or reference prior. For many models, there may be no clear choice of what to use, and employing some reference to be used automatically isn’t exactly in keeping with Bayesian thinking. In addition, such choices can still have unintended effects on the results. And finally, if you had clear prior information, e.g. from previous research, one should use it. In practice, many priors we might use could be said to be weakly informative. So instead of being completely ignorant, we can choose instead to be mostly ignorant, vague, but not too vague. As an example, consider our earlier binomial distribution example. Perhaps a reasonable guess as to the probability of making a penalty kick was .75. With that as a basis, we could choose a Beta distribution that would have roughly 80% of its probability between .6 and .9. We know that lower values for the parameters of a beta distribution represent a less informed state of mind, and the mean of the distribution is A/(A+B), so we could just fiddle with some values to see what we can turn up. The following code suggests a \\(\\mathcal{B}(9,3)\\) would probably be a good way to proceed. One can examine such a distribution in the subsequent density plot. diff(pbeta(c(.6, .9), 3, 1)) diff(pbeta(c(.6, .9), 8, 3)) diff(pbeta(c(.6, .9), 9, 3)) [1] 0.513 [1] 0.7625194 [1] 0.7915213 Thus, weakly informative priors can be based on perfectly reasonable settings, and this probably makes more sense than claiming complete ignorance, not to mention they simply work better for parameter estimation relative to flat priors. As mentioned, just some casual thought in many settings will often reveal that one isn’t completely ignorant. Furthermore, if we have clear prior information, in the form of prior research for example, we can then use informative priors based on those results. This again would be preferable to a completely noninformative approach. Conjugacy Another consideration in the choice of prior is conjugacy. Consider using the beta distribution as a prior for the binomial setting as we have done previously. It turns out that using a \\(\\beta(\\mathcal{A}, \\mathcal{B})\\) results in the following posterior: \\[p(\\theta|y, n) \\propto \\beta(y+\\mathcal{A}, n-y+\\mathcal{B})\\] Thus the posterior has the same parametric form as the prior, i.e. the beta distribution is congugate for the binomial likelihood. In this sense, the prior has the interpretation as providing additional data points. In our regression model, the conjugate setting uses a normal distribution for the predictor coefficients and an inverse gamma for \\(\\sigma^2\\). In the case of exponential family distributions of generalized linear models, there are also natural conjugate prior distributions. While there can be practical advantages to using a conjugate prior, it is not required for some estimation approaches, and for many more complex models, may not even be possible. However, it might be useful to consider a known conjugate prior as a starting point. Test your Priors Beforehand With our regression model, we were dealing with standardized predictors, so even choosing a \\(\\mathcal{N}(0, 10)\\) would be overly vague, as it would be nearly flat for the values from -1 to 1, which is the range we’d expect the coefficients to fall in. The nice part about setting the prior mean on zero is that it has a regularizing effect, shrinking coefficients toward 0, that can help avoid overfitting with smaller samples, but in that case we likely wouldn’t get much of that benefit. If we want to take advantage of this sort of knowledge, we can set up our model and priors, then sample only as if we had prior estimates. In a regression model for example, let’s say we want to check the prior for our beta coefficients. We want to test several priors, all with different variances, but otherwise centered on zero. The following uses matrix random normal samples and multiplication to quickly get the estimates. n_sim = 10 prior_beta_0_10 = replicate(4, rnorm(n_sim, mean = 0, sd = 10)) prior_beta_0_1 = replicate(4, rnorm(n_sim, mean = 0, sd = 1)) prior_beta_0_01 = replicate(4, rnorm(n_sim, mean = 0, sd = .1)) y_rep_prior_0_10 = tcrossprod(X, prior_beta_0_10) y_rep_prior_0_1 = tcrossprod(X, prior_beta_0_1) y_rep_prior_0_01 = tcrossprod(X, prior_beta_0_01) Now that we have some simulated data, compare the following plot to our observed data range for y of -6.06 to 12.43. It seems pretty clear that that one prior would be too restrictive, while the other is overly relaxed. The \\(\\mathcal{N}(0, 1)\\) seems the best choice. However, we might want to do something different for the intercept, since its value would be on a different scale than the other coefficients, and this might help shift our result to be more in line with the data48. While not all situations are not as straightforward49, hopefully this gives you an idea of how you might go about this. If using the brms package, it makes this easy with a sampling option sample_prior = 'only'. You can check out my demonstration of that process. Hierarchical Priors Not to be confused with hierarchical linear models, hierarchical in the context of Bayesian models often refers to using what are called hyperpriors, or priors on priors. Take for instance our example with regression coefficients. Maybe we wouldn’t know a good standard deviation to use. In this case we might set it as yet another parameter to be estimated, \\(\\sigma_\\beta\\), and give it a prior with lower bound of 0, e.g. \\(\\sigma_\\beta \\sim \\textrm{Half-Cauchy}(10)\\), that would have a median of 10 but will result in a final estimate of some other value. Technically this could turn into turtles all the way up, with priors upon priors upon priors. Usually one level is enough though, and might make you feel better for not setting a specific parameter to some value. Sensitivity Analysis Revisited As a reminder, we pointed out in the sensitivity analysis section of the discussion on model checking, one may perform checks on settings for the model to see if changes to them results in gross changes of inference from the posterior. Part of that check should include the choice of prior, whether different parameter values for the same distribution, or different distributions altogether. Doing such a check will give you more confidence in the final selection. A Simple Check Gelman has proposed the following as a practical check on how informative your prior might be: Here’s an idea for not getting tripped up with default priors: For each parameter (or other quantity of interest), compare the posterior sd to the prior sd. If the posterior sd for any parameter is more than 0.1 times the prior sd, then print out a note: “The prior distribution for this parameter is informative.” Then the user can go back and check that the default prior makes sense for this particular example. If you’re using rstanarm or brms, the bayestestR package will do this check for you. Summary It will not take long with a couple Bayesian texts or research articles that employ Bayesian methods to get a feel for how to go about choosing priors50. One should also remember that in the face of a lot of data, the likelihood will overwhelm the prior, rendering the choice effectively moot for simpler models. While the choice might be considered subjective in some respects, it is never arbitrary, and there are standard choices for common models and guidelines for more complex ones to help the researcher in their choice. Sampling Procedure There are many ways in which one might sample from the posterior. While Bayesian analysis is highly flexible and can solve a great many statistical models in theory, in practice things can be more difficult. As more complex models are attempted, new approaches are undertaken to deal with the problems in estimation that inevitably arise. In an attempt to dissolve at least some of the mystery, a brief description follows. Metropolis We have mentioned that BUGS and JAGS use Gibbs sampling, which is a special case of the Metropolis-Hastings (MH) algorithm51, a very general approach encompassing a wide variety of techniques. The Metropolis algorithm can be briefly described in the following steps: Start with initial values for the parameters \\(\\theta^0\\) For \\(t=1,2...N_{sim}\\) : Sample from some proposal distribution a potential candidate \\(\\theta^*\\), given \\(\\theta^{t-1}\\) Calculate the ratio \\(r\\) of the posterior densities \\(\\frac{p(\\theta^*|y)}{p(\\theta^{t-1}|y)}\\) Set \\(\\theta^t = \\theta^*\\) with probability \\(\\min(r, 1)\\), else \\(\\theta^t = \\theta^{t-1}\\) Conceptually, if the proposal increases the posterior density, \\(\\theta^t = \\theta^*\\). If it decreases the proposal density, set \\(\\theta^t = \\theta^*\\) with probability \\(r\\), else it remains at \\(\\theta^{t-1}\\). The MH algorithm generalizes the Metropolis to use asymmetric proposal distributions and uses an \\(r\\) to correct for asymmetry52. Let’s look at this in generic/pseudo R code for additional clarity (in practice we can take the difference in the log values for step 3): nsim = numberSimulatedDraws theta0 = initValue theta = c(theta0, rep(NA, nsim)) for (t in 2:nsim) { thetaStar = rnorm(1, theta[t-1], sd) u = runif(1) r = exp(logPosterior_thetaStar - logPosterior_theta0) theta[t] = ifelse(u&lt;=r, thetaStar, theta[t-1]) } One can see the Metropolis-Hastings Example to see the Metropolis algorithm applied to our regression problem. Gibbs The Gibbs sampler takes an alternating approach for multiparameter problems, sampling one parameter given the values of the others, and thus reducing a potentially high dimensional problem to lower dimensional conditional densities. We can describe its steps generally as follows. Start with initial values for some ordering of the parameters \\(\\theta_1^0, \\theta_2^0,..., \\theta_p^0\\) For \\(t=1,2..., N_{sim}\\) : At iteration \\(t\\), for \\(p=1,2..., P\\) : \\(\\theta_1^t \\sim p(\\theta_1^t | \\theta_2^{t-1}, \\theta_3^{t-1}, ..., \\theta_p^{t-1})\\) Generate \\(\\theta_2^t \\sim p(\\theta_2^t | \\theta_1^{t}, \\theta_3^{t-1}, ..., \\theta_p^{t-1})\\) \\(\\qquad\\vdots\\) Generate \\(\\theta_p^t \\sim p(\\theta_p^t | \\theta_1^{t}, \\theta_2^{t}, ..., \\theta_{p-1}^{t})\\) Again, some generic code may provide another way to understand it: for (t in 1:nsim) { for (p in 1:P) { thetaNew[p] = rDistribution(1, theta[t,-p]) } theta[t,] = thetaNew } Hamiltonian Monte Carlo Stan uses Hamiltonian Monte Carlo, another variant of MH. It takes the parameters \\(\\theta\\) as collectively denoting the position of a particle in some space with momentum \\(\\phi\\) (of same dimension as \\(\\theta\\)). Both \\(\\theta\\) and \\(\\phi\\) are updated at each Metropolis step and jointly estimated, though we are only interested in \\(\\theta\\). We can describe the basic steps as follows. At iteration \\(t\\), take a random draw of momentum \\(\\phi\\) from its posterior distribution Update the position vector \\(\\theta\\) given current momentum, update \\(\\phi\\) given the gradient of \\(\\theta\\) Calculate \\(r = \\frac{p(\\theta^*|y)p(\\phi^*)}{p(\\theta^{t-1})p(\\phi^{t-1})}\\) Set \\(\\theta^t = \\theta^*\\) with probability \\(min(r, 1)\\), else \\(\\theta^t = \\theta^{t-1}\\) The overall process allows it to move quite rapidly through the parameter space, and it can work well where other approaches such as Gibbs might be very slow. An example using HMC on the regression model data can be found in the Hamiltonian Monte Carlo Example53. Other Variations and Approximate Methods Within these MH approaches there are variations such as slice sampling, reversible jump, particle filtering, etc. Also, one can reparameterize the model to help overcome some convergence issues if applicable. In addition, there exist many approximate methods such as Variational Bayes, INLA, Approximate Bayesian Computation, etc. The main thing is just to be familiar with what’s out there in case it might be useful. Any particular method might be particularly well suited to certain models (e.g. INLA for spatial regression models), those that are notably complex, or they may just be convenient for a particular case. For a fun animated way to explore some different sampling procedures, look here. Number of draws, thinning, warm-up Whatever program we use, the typical inputs that will need to be set regard the number of simulated draws from the posterior, the number of warm-up draws, and the amount of thinning. Only the draws that remain after warm-up and thinning will be used for inference. However, there certainly is no default that would work from one situation to the next. Recall that we are looking for convergence to a distribution, and this isn’t determined by the number of draws alone. The fact is that one only needs a few draws for accurate inference. Even something as low as \\(n_{\\textrm{eff}}\\) of 10 for each chain would actually be fine assuming everything else seemed in order, though typically we want more than that so that our estimates wouldn’t bounce around a great deal from one model run to the next. To feel confident about convergence, i.e. get \\(\\hat R\\) of around 1, plots looking right, etc., we will usually want in the thousands for the number of total draws. We might need quite a few more for increasing model complexity. A conservative approach to the number of warm-up draws is to set them half the number of runs, but this is fairly arbitrary. Thinning isn’t specifically necessary for inference if approximate convergence is achieved, but is useful with increasing model complexity to reduce autocorrelation among the estimates. I mostly just use it so that the result is not so large in size. For myself, I typically run models such that the results are based on roughly \\(n_{\\textrm{eff}} = 1000\\) estimates, simply because 1000 is a nice round number, and is enough to make graphical display a bit smoother. For a regression model as we have been running, the setting we used produced 1000 final estimates across 4 chains. Other models might make due with 100000, 50000, 50 respectively. You may just need to feel things out for yourself, but for simpler models you really won’t need much. Model Complexity One of the great things about the Bayesian approach is its ability to handle extremely complex models involving lots of parameters. In addition, it will often work better (or at all) in simpler settings where the data under consideration are problematic (e.g. collinearity, separation in the logistic regression setting). While it can be quite an undertaking to set things correctly and debug, re-run fits, and generally go through the trial and error process typically associated with highly complex models, it’s definitely nice to know that you can at least attempt them. It will take some work, but you will also learn a great deal along the way. Furthermore, there are typically tips and tricks that can potentially help just about any model run a little more smoothly. It really should be a part of any analysis.↩︎ With Stan I sometimes do a 1 iteration compile check first.↩︎ The brms package does in fact automatically treat the intercept in a special manner.↩︎ Even here we’re ignoring our sigma estimate.↩︎ The BUGS book has many examples for a wide variety of applications. The Stan github page has Stan examples for each of those BUGS examples and many more.↩︎ Originally developed in physics in the 50s, it eventually made its way across to other fields.↩︎ Given a proposal/jumping distribution \\(\\mathcal{J}_t\\), \\(r=\\frac{p(\\theta^*|y)/\\mathcal{J}_t(\\theta^*|\\theta^{t-1})} {p(\\theta^{t-1}|y)/\\mathcal{J}_t(\\theta^{t-1}|\\theta^*)}\\)↩︎ See this entry at David Mimno’s blog for a visualization of HMC, and Betancourt’s Conceptual Introduction to Hamiltonian Monte Carlo.↩︎ "],["packages.html", "R Packages Standard Regression and GLM Categorical Models Extended Count Models Mixed Models Other Models and Related Even More Packages", " R Packages Here I will go into a bit of detail regarding rstanarm and brms. For standard models, these should be your first choice, rather than using Stan directly. Why? For one, the underlying code that is used will be more optimized and efficient than what you come up with, and also, that code has had multiple individuals developing it and hundreds actually using it. Furthermore, you can still, and probably should, set your priors as you wish. The nice thing about both is that you use the same syntax that you do for R modeling in general. Here is a a basic GLM in both. stan_glm(y ~ x + z, data = d) brm(y ~ x + z, data = d) And here are a couple complexities thrown in to show some minor differences. For example, the priors are specified a bit differently, and you may have options for one that you won’t have in the other, but both will allow passing standard arguments, like cores, chains, etc. to rstan. stan_glm( y ~ x + z + (1|g), data = d, family = binomial(link = &quot;logit&quot;), prior = normal(0, 1), prior_covariance = decov(regularization = 1, concentration = .5), QR = TRUE, chains = 2, cores = 2, iter = 2000 ) brm( y ~ x + z + (1|g), data = d, family = bernoulli(link = &#39;logit&#39;), prior = prior(normal(0, 1), class = b, cauchy(0, 5), class = sd), chains = 2, cores = 2, iter = 2000 ) So the syntax is easy to use for both of them, and to a point identical to standard R modeling syntax, and both have the same rstan arguments. However, you’ll need to know what’s available to tweak and how to do so specifically for each package. Standard Regression and GLM A good starting point for getting more comfortable with Bayesian analysis is to use it on what you’re already more comfortable with, e.g. the standard linear or generalized linear model, and rstanarm and brms both will do this for you. In general, for these models I would suggest rstanarm, as it will run much faster and is optimized for them. It’s not a good thing that for the most common linear models R has multiple functions and even an additional packages. So we have the following for standard linear, glm, and categorical models: aov: ANOVA lm: standard regression (linear model) glm: generalized linear model MASS::glm.nb: negative binomial for count data MASS::polr: ordinal regression model nnet::nnet: multinomial regression model biglm::biglm: big data lm rstanarm keeps this nomenclature unfortunately, and currently doesn’t offer anything for multinomial models. Thus we have: stan_aov: ANOVA stan_lm: standard regression (linear model) stan_glm: generalized linear model stan_glm.nb: negative binomial for count data or neg_binomial_2 family for stan_glm stan_polr: ordinal regression model stan_biglm: big data lm Contrast this with brms, which only requires the brm function and appropriate family, e.g. ‘poisson’ or ‘categorical,’ and which can do multinomial models also. However, if you want to do a standard linear regression, I would probably not recommend using stan_lm, as it requires a prior for the \\(R^2\\), which is unfamiliar and only explained in technical ways that are likely going to be lost on those less comfortable with, or new to, statistical or Bayesian analysis54. The good news is that you can simply run stan_glm instead, and work with the prior on the regression coefficients as we have discussed, and you can use bayes_R2 to get the \\(R^2\\). You can certainly use brms for GLM, but it would have to compile the code first, and so will always be relatively, but not prohibitively, slower. For linear models with interactions or GLM generally, you may prefer it for the marginal effects plots and other additional functionality. Categorical Models If you’re just doing a standard logistic regression, I’d suggest stan_glm, again, for the speed. In addition, it has a specific model function for conditional logistic regression (stan_clogit). Beyond that, I’d recommend brms. For ordinal regression, stan_polr goes back to requiring a prior for \\(R^2\\), which is now the \\(R^2\\) for the underlying latent variable of the ordinal outcome55. Furthermore, brms has some ordinal-specific plots, as well as other types of ordinal regression (e.g. adjacent category) that allow the proportional odds assumption to be relaxed. It also can do multi-category models. brm(y ~ x, family = &#39;categorical&#39;) # nominal outcome with &gt; 2 levels brm(y ~ cs(x), family = &#39;acat&#39;) # ordinal model with category-specific effects for x brms families for categorical: bernoulli: binary target categorical: nominal target cumulative, sratio, cratio, and acat: ordinal outcome (cumulative, stopping ratio, continuation-ratio, adjacent category) Extended Count Models For going beyond binomial, poisson, and negative binomial distributions for count data, brms has a lot more for common extensions to those models, and beyond. It also has zero-altered counterparts to continuous outcomes (e.g. hurdle_gamma). hurdle_poisson hurdle_negbinomial hurdle_gamma hurdle_lognormal zero_inflated_poisson zero_inflated_negbinomial zero_inflated_binomial zero_inflated_beta zero_one_inflated_beta As mentioned previously, there is currently no direct way to do multinomial count models[^nomulti] except via the poisson Mixed Models The Bayesian approach really shines for mixed models in my opinion, where the random effects are estimated like other parameters, and so complicated structures are notably easier to deal with, and extending such models to other distribution families is straightforward. For the usual speed boost you can use rstanarm: stan_lmer: standard lme4 style mixed model stan_glmer: glmm stan_glmer.nb: for negative binomial stan_nlmer: nlme (but see stan_gamm4) stan_mvmer: multivariate outcome stan_gamm4: generalized additive mixed model in lme4 style I would probably just recommend rstanarm for stan_lmer and stan_glmer, as brms has more flexibility, and even would be recommended for the standard models if you want to estimate residual (co-)variance structure, e.g. autocorrelation. It also will do multivariate models, and one can use mgcv::s for smooth terms in any brms model. Other Models and Related Along with all those rstanarm has specific functions for beta regression, joint mixed/survival models, and regularized linear regression. brms has many more distributional families, can do hypothesis testing[^], has marginal effects plots, and more. Both have plenty of tools for diagnostics, posterior predictive checks, and more of what has been discussed previously. In general, rstanarm is a great tool for translating your standard models into Bayesian ones in an efficient fashion. On the other hand, brms uses a simplified syntax and is notably more flexible. Here is a brief summary of my recommend use for common regression models. Analysis rstanarm brms lm √ glm √ multinomial √ ordinal √ mixed √ √ additive √ √ regularized √ √ beyond √ Besides that, if you still need to model complexity not found within those, you can still use them to generate some highly optimized starter code, as they have functions for solely generating the underlying Stan code. Even More Packages I’ve focused on the two widely-used general-purpose packages, but nothing can stop Stan at this point. As of the latest update to this document, there are now 144 other packages depending on rstan in some way. There are also interfaces for Python, Julia, and more. Odds are good you’ll find one to suit your needs. The developers note in their vignette for ANOVA:‘but it is reasonable to expect a researcher to have a plausible guess for R2 before conducting an ANOVA.’ Actually, I’m not sure how reasonable this is. In consulting I’ve seen many, many researchers of varying levels of expertise, and I don’t think even a large minority of them would be able to hazard much of a guess about \\(R^2\\) before running a model, unless they’re essentially duplicating previous work. I also haven’t come across an explanation in the documentation (which is otherwise great) of how to specify it that would be very helpful to people just starting out with Bayesian analysis or even statistics in general. If the result is that one then has to try a bunch of different priors, then that becomes the focus of the analytical effort, which likely won’t appeal to people just wanting to run a standard regression model.↩︎ If someone tells me they know what the prior should be for that, I probably would not believe them.↩︎ "],["conclusion.html", "Final Thoughts", " Final Thoughts We begin our wrap-up with a list of advantages of taking the Bayesian approach: Use of prior information Probability values and intervals have intuitive interpretation More useful and unbiased with small samples While not immune to overfitting, at least has built in regularization Can estimate complicated models that traditional approaches cannot do easily Does not rely on hypothetical data for inference Accounts for uncertainty in parameters, leading to more accurate prediction And there are many others. Traditional approaches may be easier, but that definitely does not mean better, and being easier often instills false confidence in problematic results. This is not a good thing. For the same models, traditional approaches will run faster, but for common, even complicated models we might be talking about time frames on the order of seconds, possibly undetectable if approximation methods are used. In short, there is little reason not to use Bayesian methods for most situations. Hopefully this document has provided a path toward easing into Bayesian analysis for those that are interested, but might not have had the confidence or particular skill set that many texts and courses assume. Conceptually, Bayesian inference can be fairly straightforward, and inferentially, is more akin to the ways people naturally think about probability. Many of the steps taken in classical statistical analysis are still present, but have been enriched via the incorporation of prior information, a more flexible modeling scheme, and the ability to enhance even standard analyses with new means of investigation. Of course, it will not necessarily be easy, particularly for complex models, though such models might actually be relatively easier compared to the classical framework. While not necessary for all models, oftentimes the process will involve a more hands-on approach. However, this allows for more understanding of the model and its results, and gets easier with practice just like anything else. You certainly don’t have to abandon classical and other methods either. Scientific research involves applying the best tool for the job, and in some cases the Bayesian approach may not be the best fit for a particular problem. But when it is, it’s hoped you’ll be willing to take the plunge, and know there are many tools and a great community of people to help you along the way. … infinite skills create miracles… "],["appendix.html", "Appendix Maximum Likelihood Review Linear Model Binomial Likelihood Example Modeling Languages BUGS Example JAGS Example Metropolis Hastings Example Hamiltonian Monte Carlo Example", " Appendix Maximum Likelihood Review This is a very brief refresher on maximum likelihood estimation using a standard regression approach as an example. Given the likelihood’s role in Bayesian estimation and statistics in general, and the ties between specific Bayesian results and maximum likelihood estimates one typically comes across, one should be conceptually comfortable with some basic likelihood estimation. In the standard model setting we attempt to find parameters \\(\\theta\\) that will maximize the probability of the data we actually observe. We’ll start with an observed random target vector \\(y\\) with \\(i...N\\) independent and identically distributed observations and some data-generating process underlying it \\(f(\\cdot|\\theta)\\). The key idea is that we are interested in estimating the model parameter(s), \\(\\theta\\), that would make the data most likely to have occurred. The probability density function for an observed value of \\(y\\) given some particular estimate for the parameters can be noted as \\(f(y_i|\\theta)\\). The joint probability distribution of the (independent) observations given those parameters is the product of the individual densities, and this is our basic likelihood function. We can write it out generally as: \\[\\mathcal{L}(\\theta) = \\prod_{i=1}^N f(y_i|\\theta)\\] So the likelihood for one set of parameter estimates given a fixed set of data y, is equal to the probability of the data given those (fixed) estimates. Furthermore, we can compare one set, \\(\\mathcal{L}(\\theta_A)\\), to that of another, \\(\\mathcal{L}(\\theta_B)\\), and whichever produces the greater likelihood would be the preferred set of estimates. We can get a sense of this with the following visualization, based on a single parameter, Poisson distributed variable. The data is drawn from a variable with mean \\(\\theta=5\\). We note the calculated likelihood increases as we estimate values for \\(\\theta\\) closer to \\(5\\). With more and more data, the final ML estimate will converge on the true value. Final estimate = 5.02 For computational reasons, we instead work with the sum of the natural log probabilities56, and thus the log likelihood: \\[\\ln\\mathcal{L}(\\theta) = \\sum_{i=1}^N \\ln[f(y_i|\\theta)]\\] Concretely, we calculate a log likelihood for each observation and then sum them for the total likelihood for parameter(s) \\(\\theta\\). The likelihood function incorporates our assumption about the sampling distribution of the data given some estimate for the parameters. It can take on many forms and be notably complex depending on the model in question, but once specified, we can use any number of optimization approaches to find the estimates of the parameter that make the data most likely. As an example, for a normally distributed variable of interest we can write the log likelihood as follows: \\[\\ln\\mathcal{L}(\\theta) = \\sum_{i=1}^N \\ln[\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp(-\\frac{(y-\\mu)^2}{2\\sigma^2})]\\] Example In the following we will demonstrate the maximum likelihood approach to estimation for a simple setting incorporating a normal distribution, where we estimate the mean and variance/sd for a set of values \\(y\\)57. First the data is created, and then we create the function that will compute the log likelihood. Using the built in R distributions58 makes it fairly straightforward to create our own likelihood function and feed it into an optimization function to find the best parameters. We will set things up to work with the bbmle package, which has some nice summary functionality and other features. However, one should take a glance at optim and the other underlying functions that do the work. # for replication set.seed(1234) # create the data y = rnorm(1000, mean = 5, sd = 2) startvals = c(0, 1) # the log likelihood function LL = function(mu = startvals[1], sigma = startvals[2], verbose = TRUE) { ll = -sum(dnorm(y, mean = mu, sd = sigma, log = TRUE)) if (verbose) message(paste(mu, sigma, ll)) ll } The LL function takes starting points for the parameters as arguments, in this case we call them \\(\\mu\\) and \\(\\sigma\\), which will be set to 0 and 1 respectively. Only the first line (ll = -sum…) is actually necessary, and we use dnorm to get the density for each point59. Since this optimizer is by default minimization, we reverse the sign of the sum so as to minimize the negative log likelihood, which is the same as maximizing the likelihood. Note that the bit of other code just allows you to see the estimates as the optimization procedure searches for the best values. I do not show that here, but you’ll see it in your console if verbose=TRUE. We are now ready to obtain maximum likelihood estimates for the parameters. For the mle2 function we will need the function we’ve created, plus other inputs related to that function or the underlying optimizing function used (by default optim). In this case we will use an optimization procedure that will allow us to set a lower bound for \\(\\sigma\\). This isn’t strictly necessary, but otherwise you would get warnings and possibly lack of convergence if negative estimates for \\(\\sigma\\) were allowed60. library(bbmle) # using optim, and L-BFGS-B so as to constrain sigma to be positive by setting # the lower bound at zero mlnorm = mle2( LL, start = list(mu = 2, sigma = 1), method = &quot;L-BFGS-B&quot;, lower = c(sigma = 0) ) mlnorm Call: mle2(minuslogl = LL, start = list(mu = 2, sigma = 1), method = &quot;L-BFGS-B&quot;, lower = c(sigma = 0)) Coefficients: mu sigma 4.946803 1.993680 Log-likelihood: -2108.92 # compare to an intercept only regression model broom::tidy(lm(y ~ 1)) # A tibble: 1 × 5 term estimate std.error statistic p.value &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) 4.95 0.0631 78.4 0 We can see that the ML estimates are the same as the intercept only model estimates61, which given the sample size are close to the true values. In terms of the parameters we estimate, in the typical case of two or more parameters we can think of a likelihood surface that represents the possible likelihood values given any particular set of estimates. Given some starting point, the optimization procedure then travels along the surface looking for a minimum/maximum point62. For simpler settings such as this, we can visualize the likelihood surface and its minimum point. The optimizer travels along this surface until it finds a minimum (the surface plot is interactive- feel free to adjust). I also plot the path of the optimizer from a top down view. The large blue dot noted represents the minimum negative log likelihood. A bit of jitter was added to the points to better see what’s going on. Please note that there are many other considerations in optimization completely ignored here, but for our purposes and the audience for which this is intended, we do not want to lose sight of the forest for the trees. We now move next to a slightly more complicated regression example. Linear Model In the standard regression context, the expected value for the target variable comes from our linear predictor, i.e. the weighted combination of our explanatory variables, and we estimate the regression weights/coefficients and possibly other relevant parameters. We can expand our previous example to the standard linear model without too much change. In this case we estimate a mean for each observation, but otherwise assume the variance is constant across observations. Again, we first construct some data so that we know exactly what to expect, then write out the likelihood function with starting parameters. As we need to estimate our intercept and coefficient for the X predictor (collectively referred to as \\(\\beta\\)), we can think of our likelihood explicitly as before: \\[\\ln\\mathcal{L}(\\beta, \\sigma^2) = \\sum_{i=1}^N \\ln[\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp(-\\frac{(y-X\\beta)^2}{2\\sigma^2})]\\] # for replication set.seed(1234) # predictor X = rnorm(1000) # coefficients for intercept and predictor beta = c(5, 2) # add intercept to X and create y with some noise y = cbind(1, X) %*% beta + rnorm(1000, sd = 2.5) regLL = function(sigma = 1, Int = 0, b1 = 0){ coefs = c(Int, b1) mu = cbind(1, X) %*% coefs ll = -sum(dnorm(y, mean = mu, sd = sigma, log = TRUE)) message(paste(sigma, Int, b1, ll)) ll } library(bbmle) mlopt = mle2(regLL, method = &quot;L-BFGS-B&quot;, lower = c(sigma = 0)) summary(mlopt) Maximum likelihood estimation Call: mle2(minuslogl = regLL, method = &quot;L-BFGS-B&quot;, lower = c(sigma = 0)) Coefficients: Estimate Std. Error z value Pr(z) sigma 2.447823 0.054735 44.721 &lt; 2.2e-16 *** Int 5.039976 0.077435 65.087 &lt; 2.2e-16 *** b1 2.139284 0.077652 27.549 &lt; 2.2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 -2 log L: 4628.273 # plot(profile(mlopt), absVal = FALSE) modlm = lm(y ~ X) broom::tidy(modlm) # A tibble: 2 × 5 term estimate std.error statistic p.value &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) 5.04 0.0775 65.0 0 2 X 2.14 0.0777 27.5 1.58e-124 -2 * logLik(modlm) &#39;log Lik.&#39; 4628.273 (df=3) As before, our estimates and final log likelihood value are about where they should be, and reflect the lm output, as the OLS estimates are the maximum likelihood estimates. The visualization becomes more difficult beyond two parameters, but we can examine slices similar to the previous plot. To move to generalized linear models, very little changes of the process. We will have a potentially different distribution assumed, and we are typically modeling a function of the target variable (e.g. \\(\\log(y)=X\\beta; \\mu = e^{X\\beta}\\)). Binomial Likelihood Example This regards the example seen in the early part of the document with the hands-on example. x1 = rbinom(1000, size = 10, p = .5) x2 = rbinom(1000, size = 10, p = .85) binomLL = function(theta, x) { -sum(dbinom(x, size = 10, p = theta, log = TRUE)) } optimize(binomLL, x = x1, lower = 0, upper = 1) $minimum [1] 0.5043001 $objective [1] 1902.557 mean(x1) [1] 5.043 optimize(binomLL, x = x2, lower = 0, upper = 1) $minimum [1] 0.8568963 $objective [1] 1438.786 mean(x2) [1] 8.569 Modeling Languages I will talk only briefly about a couple of the modeling language options available, as you will have to make your own choice among many. Bugs When I first wrote this document, BUGS (Lunn et al. 2012) (Bayesian inference Using Gibbs Sampling) was perhaps the most widely known and used Bayesian modeling language, and it has been around for over 30 years at this point. It is implemented via OpenBUGS and freely available for download63. It even has a GUI interface if such a thing is desired. JAGS JAGS (Just Another Gibbs Sampler) is a more recent dialect of the BUGS language, and is also free to use. It offers some technical and modeling advantages to OpenBUGs, but much of the code translates directly from one to the other. Nimble Nimble allows one to implement BUGS style models within R, but also is highly extensible and provides additional options. Stan Stan is a relative newcomer to Bayesian modeling languages, and as I write this it is about to have its 10 year anniversary. It uses a different estimation procedure than the BUGS language, and this makes it more flexible and perhaps better behaved for many types of models. It actually compiles Stan code to C++, and so can be very fast as well. In addition, it has interfaces for Python, Julia and more. I personally prefer it as I find it more clear in its expression, and there are many associated tools for model exploration. R R has many modeling packages devoted to Bayesian analysis such that there is a Task View specific to the topic. Most of them are even specific to the implementation of a certain type of analysis64. So not only can you do everything within R and take advantage of the power of those languages, you can then use Bayesian specific R packages on the results. For standard and even some complex models I would suggest using the rstanarm or brms packages as a way to stick to the usual R modeling style, unless you have a notably complicated model, at which point you can use rstan. General Statistical Packages The general statistical languages such as SAS, SPSS, and Stata were generally very late to the Bayesian game, even for implementations of Bayesian versions of commonly used models. SAS and Stata are fairly capable from what I can tell (but there is StataStan). Others still seem to be lacking as well. In general, I wouldn’t recommend these packages for Bayesian analysis, except as an interface to one of the Bayesian specific languages, assuming they have the capability and you are already familiar with the program. Other Programming Languages Python has functionality via modules such as PyMC, and Stan has a Python implementation, PyStan. Julia and Matlab both have Stan ports as well. And with any programming language that you might use for statistical analysis, you could certainly do a lot of it by hand if you have the time, though you should exhaust tested implementations first. Summary In short, you have plenty of options. I would suggest starting with a Bayesian programming language or using that language within your chosen statistical environment or package. This gives you the most modeling flexibility, choice, and opportunity to learn. BUGS Example The following provides a BUGS example65 of the primary model used in this document. The applicable code for the data set up is in the Example: Linear Regression Model section of the document. The model matrix X must be a matrix class object. Next we setup a BUGS data list as we did with Stan, and create a text file that contains the model code. Note that the data list comprises simple characters which are used to look for objects of those names that are in the environment. Also, I use cat with sink so that I don’t have to go to a separate text editor to create the file. One of the big differences between BUGS and other languages is its use of the precision parameter \\(\\frac{1}{\\sigma^2}\\), the inverse variance, usually denoted as \\(\\tau\\). While there were some computational niceties to be had in doing so, even the authors admit this was not a good decision in retrospect. Prepare to have that issue come up from time to time when you inevitably forget. Comments and assignments are the same as R, and distributions noted with \\(\\sim\\). bugsdat = list(&#39;y&#39;, &#39;X&#39;, &#39;N&#39;, &#39;K&#39;) # This will create a file, lmbugs.txt that will subsequently be called sink(&#39;data/lmbugs.txt&#39;) cat( &#39;model { for (n in 1:N){ mu[n] &lt;- beta[1]*X[n,1] + beta[2]*X[n,2] + beta[3]*X[n,3] + beta[4]*X[n,4] y[n] ~ dnorm(mu[n], inv.sigma.sq) } for (k in 1:K){ beta[k] ~ dnorm(0, .001) # prior for reg coefs } # Half-cauchy as in Gelman 2006 # Scale parameter is 5, so precision of z = 1/5^2 = 0.04 sigma.y &lt;- abs(z)/sqrt(chSq) # prior for sigma; cauchy = normal/sqrt(chi^2) z ~ dnorm(0, .04)I(0,) chSq ~ dgamma(0.5, 0.5) # chi^2 with 1 d.f. inv.sigma.sq &lt;- pow(sigma.y, -2) # precision # sigma.y ~ dgamma(.001, .001) # prior for sigma; a typical approach used. }&#39; ) sink() # explicitly provided initial values not necessary, but one can specify them # as follows, and you may have problems with variance parameters if you don&#39;t. # Note also that sigma.y is unnecesary if using the half-cauchy approach as # it is defined based on other values. # inits &lt;- list(list(beta=rep(0,4), sigma.y=runif(1,0,10)), # list(beta=rep(0,4), sigma.y=runif(1,0,10)), # list(beta=rep(0,4), sigma.y=runif(1,0,10))) # parameters &lt;- c(&#39;beta&#39;, &#39;sigma.y&#39;) Now we are ready to run the model. You’ll want to examine the help file for the bugs function for more information. In addition, depending on your setup you may need to set the working directory and other options. Note that n.thin argument is used differently than other packages. One specifies the n posterior draws (per chain) you to keep want as n.iter-n.burnin. The thinned samples aren’t stored. Compare this to other packages where n.iter is the total before thinning and including burn-in, and n.keep is (n.iter-n.burnin)/n.thin. With the function used here, n.keep is the same, but as far as arguments your you’ll want to think of n.iter as the number of posterior draws after thinning. So the following all produce 1000 posterior draws in R2OpenBUGS: n.iter = 3000 n.thin = 1 n.burnin = 2000 n.iter = 3000 n.thin = 10 n.burnin = 2000 n.iter = 3000 n.thin = 100 n.burnin = 2000 In other packages, with those arguments you’d end up with 1000, 100, and 10 posterior draws. library(R2OpenBUGS) lmbugs &lt;- bugs( bugsdat, inits = NULL, parameters = c(&#39;beta&#39;, &#39;sigma.y&#39;), model.file = &#39;lmbugs.txt&#39;, n.chains = 3, n.iter = 3000, n.thin = 10, n.burnin = 2000 ) Now we are ready for the results, which will be the same as what we saw with Stan. In addition to the usual output, you get the deviance information criterion as a potential means for model comparison. ## lmbugs$summary mean sd 2.5% 50% 97.5% Rhat n.eff beta[1] 4.90 0.13 4.65 4.90 5.14 1 2400 beta[2] 0.08 0.13 -0.17 0.08 0.34 1 3000 beta[3] -1.47 0.13 -1.72 -1.47 -1.22 1 2100 beta[4] 0.82 0.12 0.59 0.83 1.05 1 3000 sigma.y 2.03 0.09 1.86 2.02 2.22 1 3000 deviance 1063.61 3.15 1059.00 1063.00 1071.00 1 3000 The usual model diagnostics are available with conversion of the results to a general MCMC object, here shown via the the posterior package. You can then use bayesplot or other visualization tools. Figures are not shown, but they are the typical traceplots and density plots. bugs_samples = posterior::as_draws(lmbugs$sims.array) posterior::summarise_draws(bugs_samples) posterior::rstar(bugs_samples) bayesplot::mcmc_trace(bugs_samples) bayesplot::mcmc_dens(bugs_samples) JAGS Example The following shows how to run the regression model presented earlier in the document via JAGS. Once you have the data set up as before, the data list is done in the same fashion as with BUGS. The code itself is mostly identical, save for the use of T instead of I for truncation. JAGS, being a BUGS dialect, also uses the precision parameter in lieu of the variance, which isn’t annoying at all. jagsdat = list( &#39;y&#39; = y, &#39;X&#39; = X, &#39;N&#39; = N, &#39;K&#39; = K ) sink(&#39;data/lmjags.txt&#39;) cat( &#39;model { for (n in 1:N){ mu[n] &lt;- beta[1] * X[n, 1] + beta[2] * X[n, 2] + beta[3] * X[n, 3] + beta[4] * X[n, 4] y[n] ~ dnorm(mu[n], inv.sigma.sq) } for (k in 1:K){ beta[k] ~ dnorm(0, .001) } # Half-cauchy as in Gelman 2006 # Scale parameter is 5, so precision of z = 1/5^2 = 0.04 sigma.y &lt;- z/sqrt(chSq) z ~ dnorm(0, .04)T(0,) chSq ~ dgamma(0.5, 0.5) inv.sigma.sq &lt;- pow(sigma.y, -2) }&#39; ) sink() # explicitly provided initial values not necessary, but can specify as follows # inits &lt;- function() { # list(beta = rep(0, 4), sigma.y = runif(1, 0, 10)) # } parameters = c(&#39;beta&#39;, &#39;sigma.y&#39;) With everything set, we can now run the model. With JAGS, we have what might be called an initialization stage that sets the model up and runs through the warm-up period, after which we can then flexibly sample from the posterior via the coda.samples function. library(rjags) # library(coda) lmjagsmod = jags.model( file = &#39;data/lmjags.txt&#39;, data = jagsdat, n.chains = 3, n.adapt = 2000 # inits = inits # if you use them ) lmjags = coda.samples( model = lmjagsmod, n.iter = 10000, thin = 10, n.chains = 3, variable.names = parameters ) Now we have a model identical to the others, and can summarize the posterior distribution in similar fashion. As before, you can use the posterior and other packages as well. summary(lmjags) coda::effectiveSize(lmjags) term estimate std.error conf.low conf.high ESS beta[1] 4.89 0.13 4.64 5.15 3000.00 beta[2] 0.08 0.13 -0.17 0.34 3453.26 beta[3] -1.47 0.13 -1.71 -1.22 3000.00 beta[4] 0.82 0.12 0.57 1.06 3000.00 sigma.y 2.02 0.09 1.86 2.22 3000.00 Metropolis Hastings Example Next depicted is a random walk Metropolis-Hastings algorithm using the data and model from prior sections of the document. I had several texts open while cobbling together this code such as Gelman et al. (2013), and some oriented towards the social sciences by Gill (2008), Jackman (2009), and Lynch (2007) etc. Some parts of the code reflect information and code examples found therein, and follows Lynch’s code a bit more66. The primary functions that we need to specify regard the posterior distribution67, an update step for beta coefficients, and an update step for the variance estimate. # posterior function post = function(x, y, b, s2) { # Args: X is the model matrix; y the target vector; b and s2 the parameters # to be estimated beta = b sigma = sqrt(s2) sigma2 = s2 mu = X %*% beta # priors are b0 ~ N(0, sd = 10), sigma2 ~ invGamma(.001, .001) priorbvarinv = diag(1/100, 4) prioralpha = priorbeta = .001 if (is.nan(sigma) | sigma &lt;= 0) { # scale parameter must be positive return(-Inf) } # Note that you will not find the exact same presentation across texts and # other media for the log posterior in this conjugate setting. In the end # they are conceptually still (log) prior + (log) likelihood (See commented &#39;else&#39;) else { -.5*nrow(X)*log(sigma2) - (.5*(1/sigma2) * (crossprod(y-mu))) + -.5*ncol(X)*log(sigma2) - (.5*(1/sigma2) * (t(beta)%*%priorbvarinv%*%beta)) + -(prioralpha+1)*log(sigma2) + log(sigma2) - priorbeta/sigma2 } # else { # ll = mvtnorm::dmvnorm( # y, # mean = mu, # sigma = diag(sigma2, length(y)), # log = TRUE # ) # # priorb = mvtnorm::dmvnorm( # beta, # mean = rep(0, length(beta)), # sigma = diag(100, length(beta)), # log = TRUE # ) # # priors2 = dgamma(1 / sigma2, prioralpha, priorbeta, log = TRUE) # # logposterior = ll + priorb + priors2 # logposterior # } } # update step for regression coefficients updatereg = function(i, x, y, b, s2) { # Args are the same as above but with additional i iterator argument. b[i,] = MASS::mvrnorm(1, mu = b[i-1, ], Sigma = bvarscale) # proposal/jumping distribution # Compare to past- does it increase the posterior probability? postdiff = post(x = x, y = y, b = b[i, ], s2 = s2[i-1]) - post(x = x, y = y, b = b[i-1, ], s2 = s2[i-1]) # Acceptance phase unidraw = runif(1) accept = unidraw &lt; min(exp(postdiff), 1) # accept if so if (accept) b[i,] else b[i-1,] } # update step for sigma2 updates2 = function(i, x, y, b, s2) { s2candidate = rnorm(1, s2[i-1], sd = sigmascale) if (s2candidate &lt; 0) { accept = FALSE } else { s2diff = post(x = x, y = y, b = b[i, ], s2 = s2candidate) - post(x = x, y = y, b = b[i, ], s2 = s2[i-1]) unidraw = runif(1) accept = unidraw &lt; min(exp(s2diff), 1) } ifelse(accept, s2candidate, s2[i-1]) } Now we can set things up for the MCMC chain68. Aside from the typical MCMC setup and initializing the parameter matrices to hold the draws from the posterior, we also require scale parameters to use for the jumping/proposal distribution. # Setup, starting values etc. nsim = 5000 burnin = 1000 thin = 10 b = matrix(0, nsim, ncol(X)) # initialize beta update matrix s2 = rep(1, nsim) # initialize sigma vector # For the following this c term comes from BDA3 12.2 and will produce an # acceptance rate of .44 in 1 dimension and declining from there to about # .23 in high dimensions. For the sigmascale, the magic number comes from # starting with a value of one and fiddling from there to get around .44. c = 2.4/sqrt(ncol(b)) bvar = vcov(lm(y ~ ., data.frame(X[, -1]))) bvarscale = bvar * c^2 sigmascale = .9 We can now run and summarize the model with tools from the coda package. # Run for (i in 2:nsim) { b[i, ] = updatereg( i = i, y = y, x = X, b = b, s2 = s2 ) s2[i] = updates2( i = i, y = y, x = X, b = b, s2 = s2 ) } # calculate acceptance rates b_acc_rate = mean(diff(b[(burnin + 1):nsim,]) != 0) s2_acc_rate = mean(diff(s2[(burnin + 1):nsim]) != 0) tibble(b_acc_rate, s2_acc_rate) # get final chain library(posterior) b_final = as_draws(b[seq(burnin + 1, nsim, by = thin), ]) s2_final = as_draws(matrix(s2[seq(burnin + 1, nsim, by = thin)])) # get summaries; compare to lm and stan summarise_draws(b_final) summarise_draws(s2_final) round(c(coef(modlm), summary(modlm)$sigma ^ 2), 3) variable mean sd mcse q2.5 q97.5 rhat ess_bulk ess_tail beta.1 4.90 0.13 0.01 4.64 5.14 1.00 276.19 331.70 beta.2 0.09 0.14 0.01 -0.16 0.36 1.00 228.91 207.34 beta.3 -1.46 0.13 0.01 -1.70 -1.21 1.00 311.59 273.93 beta.4 0.82 0.13 0.01 0.59 1.05 1.00 286.56 283.76 s2 4.09 0.37 0.02 3.42 4.86 1.03 396.93 390.88 Here is the previous Stan fit for comparison. term estimate std.error conf.low conf.high beta[1] 4.90 0.13 4.63 5.14 beta[2] 0.09 0.13 -0.18 0.34 beta[3] -1.47 0.13 -1.72 -1.22 beta[4] 0.82 0.12 0.58 1.06 sigma 2.03 0.09 1.86 2.22 Hamiltonian Monte Carlo Example The following demonstrates Hamiltonian Monte Carlo, the technique that Stan uses, and which is a different estimation approach than the Gibbs sampler in BUGS/JAGS. If you are interested in the details enough to be reading this, I highly recommend Betancourt’s conceptual introduction to HMC. This example still assumes the data we used in this document, and is largely based on the code in the appendix of Gelman et al. (2013). First we start with the functions. # Log posterior function log_p_th = function(X, y, theta) { # Args: X is the model matrix; y the target vector; theta are the current # parameter estimates. beta = theta[-length(theta)] # reg coefs to be estimated sigma = theta[length(theta)] # sigma to be estimated sigma2 = sigma^2 mu = X %*% beta # priors are b0 ~ N(0, sd=10), sigma2 ~ invGamma(.001, .001) priorbvarinv = diag(1/100, 4) prioralpha = priorbeta = .001 if (is.nan(sigma) | sigma&lt;=0) { # scale parameter must be positive, so posterior return(-Inf) # density is zero if it jumps below zero } # log posterior in this conjugate setting. conceptually it&#39;s # (log) prior + (log) likelihood. (See commented &#39;else&#39;) else { -.5*nrow(X)*log(sigma2) - (.5*(1/sigma2) * (crossprod(y-mu))) + -.5*ncol(X)*log(sigma2) - (.5*(1/sigma2) * (t(beta)%*%priorbvarinv%*%beta)) + -(prioralpha+1)*log(sigma2) + log(sigma2) - priorbeta/sigma2 } # else { # ll = mvtnorm::dmvnorm( # y, # mean = mu, # sigma = diag(sigma2, length(y)), # log = TRUE # ) # priorb = mvtnorm::dmvnorm( # beta, # mean = rep(0, length(beta)), # sigma = diag(100, length(beta)), # log = TRUE # ) # priors2 = dgamma(1/sigma2, prioralpha, priorbeta, log = TRUE) # logposterior = ll + priorb + priors2 # logposterior # } } # numerical gradient function as given in BDA3 p. 602; same args as posterior gradient_theta_numerical = function(X, y, theta) { d = length(theta) e = .0001 diffs = numeric(5) for (k in 1:d) { th_hi = theta th_lo = theta th_hi[k] = theta[k] + e th_lo[k] = theta[k] - e diffs[k] = (log_p_th(X, y, th_hi) - log_p_th(X, y, th_lo)) / (2*e) } return(diffs) } # single HMC iteration function hmc_iteration = function( X, y, theta, epsilon, L, M ) { # Args: epsilon is the stepsize; L is the number of leapfrog steps; epsilon # and L are drawn randomly at each iteration to explore other areas of the # posterior (starting with epsilon0 and L0); M is a diagonal mass matrix # (expressed as a vector), a bit of a magic number in this setting. It regards # the mass of a particle whose position is represented by theta, and momentum # by phi. See the sampling section of chapter 1 in the Stan manual for more # detail. M_inv = 1/M d = length(theta) phi = rnorm(d, 0, sqrt(M)) th_old = theta log_p_old = log_p_th(X, y, theta) - .5*sum(M_inv*phi^2) phi = phi + .5 * epsilon * gradient_theta_numerical(X, y, theta) for (l in 1:L) { theta = theta + epsilon*M_inv*phi phi = phi + ifelse(l == L, .5, 1) * epsilon * gradient_theta_numerical(X, y, theta) } # here we get into standard MCMC stuff, jump or not based on a draw from a # proposal distribution phi = -phi log_p_star = log_p_th(X, y, theta) - .5 * sum(M_inv * phi^2) r = exp(log_p_star - log_p_old) if (is.nan(r)) r = 0 p_jump = min(r, 1) if (runif(1) &lt; p_jump) { th_new = theta } else { th_new = th_old } return(list(theta = th_new, p_jump = p_jump)) # returns estimates and acceptance rate } # main HMC function hmc_run = function( starts, # starting values for theta iter, # total number of simulations for each chain; chain is based on the dimension of starts warmup, # determines initial iterations that will be ignored for inference purposes epsilon_0, # the baseline stepsize L_0, # the baseline number of leapfrog steps M, # the mass vector X, y ) { # Args: chains = nrow(starts) d = ncol(starts) sims = array(NA, c(iter, chains, d), dimnames = list(NULL, NULL, colnames(starts))) p_jump = matrix(NA, iter, chains) for (j in 1:chains) { theta = starts[j, ] for (t in 1:iter) { epsilon = runif(1, 0, 2 * epsilon_0) L = ceiling(2 * L_0 * runif(1)) temp = hmc_iteration(X, y, theta, epsilon, L, M) p_jump[t, j] = temp$p_jump sims[t, j,] = temp$theta theta = temp$theta } } # rstan::monitor(sims, warmup, digits_summary=3) acc = round(colMeans(p_jump[(warmup + 1):iter,]), 3) # acceptance rate message( &#39;Avg acceptance probability for each chain: &#39;, paste0(acc[1], &#39;, &#39;, acc[2]), &#39;\\n&#39; ) return(list(sims = sims, p_jump = p_jump)) } With the primary functions in place, we set the starting values and choose other settings for for the HMC process. The coefficient starting values are based on random draws from a uniform distribution, while \\(\\sigma\\) is set to a value of one in each case. For this example we’ll have 2000 total draws with warm-up set to 1000. I don’t have any thinning option here, but that could be added or simply done as part of the coda package preparation. # Starting values and mcmc settings parnames = c(paste0(&#39;beta[&#39;, 1:4, &#39;]&#39;), &#39;sigma&#39;) d = length(parnames) chains = 2 thetastart = t(replicate(chains, c(runif(d-1, -1, 1), 1))) colnames(thetastart) = parnames nsim = 2000 warmup = 1000 # fiddle with these to get a desirable acceptance rate of around .80. The # following work well with the document data. stepsize = .08 nLeap = 10 We are now ready to run the model. On my machine and with the above settings, this took a couple seconds. Once complete, we can use the posterior package as we have done before. # Run the model fit_hmc = hmc_run( starts = thetastart, iter = nsim, warmup = warmup, epsilon_0 = stepsize, L_0 = nLeap, M = mass_vector, X = X, y = y ) # str(fit_hmc, 1) # use posterior to summarize the two chains library(posterior) theta = as_draws_array(fit_hmc$sims[(warmup + 1):nsim, , ]) summarise_draws(theta) finalest = summary(theta)$mean b = finalest[1:4] sig = finalest[5] # log posterior log_p_th(X, y, finalest) Avg acceptance probability for each chain: 0.823, 0.814 variable mean sd mcse q2.5 q97.5 rhat ess_bulk ess_tail beta[1] 4.90 0.12 0 4.66 5.13 1.01 1261.80 892.17 beta[2] 0.09 0.13 0 -0.16 0.33 1.00 1204.27 792.15 beta[3] -1.47 0.13 0 -1.71 -1.23 1.00 1308.67 1039.06 beta[4] 0.82 0.13 0 0.55 1.07 1.01 1247.88 826.81 sigma 2.01 0.09 0 1.85 2.18 1.00 1389.68 1051.83 log posterior = -301.716 Our estimates look pretty good, and inspection of the diagnostics would show good mixing and convergence as well. At this point we can compare it to the Stan output. For the following, I modified the previous Stan code to use the same inverse gamma prior and tweaked the control options for a little bit more similarity. term estimate std.error conf.low conf.high beta[1] 4.90 0.13 4.64 5.14 beta[2] 0.08 0.13 -0.17 0.34 beta[3] -1.47 0.13 -1.72 -1.22 beta[4] 0.82 0.12 0.58 1.06 sigma 2.02 0.09 1.86 2.22 log posterior = -301.532 References "],["references.html", "References Texts for Your Shelf Stan Specific Resources Works Cited/Used", " References Texts for Your Shelf The following are three texts I have recommended in the past to folks who are interested in doing Bayesian data analysis. They can be seen as introduction, intermediate, and advanced respectively. Kruschke, J. (2014) Doing Bayesian Data Analysis. A very introductory text, but might be good for those not too confident in statistics generally speaking. And who doesn’t like puppies? 2nd Edition. McElreath, R. (2020). Statistical Rethinking. A great modeling book in general, by one who has contributed a lot to helping others learn Stan and Bayesian analysis. 2nd Edition. Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., and Rubin, D. B. (2013). Bayesian Data Analysis. 3rd Edition. Stan Specific Resources Main website Stan Users Group Stan Best Practices Example Models More resources here Works Cited/Used "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
