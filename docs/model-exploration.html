<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Chapter 5 Model Exploration | Bayesian Basics</title>

  
   <meta name="description" content="This document provides an introduction to Bayesian data analysis. It is conceptual in nature, but uses the probabilistic programming language Stan for demonstration (and its implementation in R via rstan). From elementary examples, guidance is provided for data preparation, efficient modeling, diagnostics, and more." />
   <meta name="generator" content="placeholder" />
  <meta property="og:title" content="Chapter 5 Model Exploration | Bayesian Basics" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://m-clark.github.io/bayesian-basics/" />
  <meta property="og:image" content="https://m-clark.github.io/bayesian-basics//img/nineteeneightyR.png" />
  <meta property="og:description" content="This document provides an introduction to Bayesian data analysis. It is conceptual in nature, but uses the probabilistic programming language Stan for demonstration (and its implementation in R via rstan). From elementary examples, guidance is provided for data preparation, efficient modeling, diagnostics, and more." />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Model Exploration | Bayesian Basics" />
  
  <meta name="twitter:description" content="This document provides an introduction to Bayesian data analysis. It is conceptual in nature, but uses the probabilistic programming language Stan for demonstration (and its implementation in R via rstan). From elementary examples, guidance is provided for data preparation, efficient modeling, diagnostics, and more." />
  <meta name="twitter:image" content="https://m-clark.github.io/bayesian-basics//img/nineteeneightyR.png" />
  <!-- JS -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script>
  <script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script>
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet" />
    <script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script>
    <script src="libs/bs3compat-0.3.1/transition.js"></script>
    <script src="libs/bs3compat-0.3.1/tabs.js"></script>
    <script src="libs/bs3compat-0.3.1/bs3compat.js"></script>
    <link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet" />
    <script src="libs/bs4_book-1.0.0/bs4_book.js"></script>
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
    <script src="libs/plotly-binding-4.10.0/plotly.js"></script>
    <script src="libs/typedarray-0.1/typedarray.min.js"></script>
    <link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
    <script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
    <link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
    <script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script>

  <!-- CSS -->
  
</head>

<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book">
    <a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Bayesian Basics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
      </form>

      <nav aria-label="Table of contents">
        <h2>Table of contents</h2>
        <div id="book-toc"></div>

        <div class="book-extra">
          <p><a id="book-repo" href="#">View book source <i class="fab fa-github"></i></a></li></p>
        </div>
      </nav>
    </div>
  </header>

  <main class="col-sm-12 col-md-9 col-lg-7" id="content">
<div id="model-exploration" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> Model Exploration</h1>
<p>As with modeling in traditional approaches, it is not enough to simply run a model and go with whatever results are returned without further inspection. One must examine the results to assess model integrity and have more confidence in the results that have been produced<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a>.</p>
<div id="monitoring-convergence" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Monitoring Convergence</h2>
<p>There are various ways to assess whether or not the model has converged to a target distribution<a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a>, but as with more complex models in MLE, there is nothing that can tell you for sure that you’ve hit upon the true solution. As a starting point, Stan or other modeling environments will likely return repeated warnings or errors if something is egregiously wrong, or perhaps take an extraordinarily long time to complete relative to expectations, if it ever finishes at all. Assuming you’ve at least gotten past that point, there is more to be done.</p>
<div id="visual-inspection-traceplot-densities" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Visual Inspection: Traceplot &amp; Densities</h3>
<p>In the previous model we noted the traceplot for a single parameter, and a visual approach to monitoring convergence is certainly one good method. In general, we look for a plot that shows random scatter around a mean value, and our model results suggest that the chains mixed well and the traceplot looked satisfactory.</p>
<p><img  src="img/badchains.svg" style="display:block; margin: 0 auto;"  width=50%></p>
<p>This above shows an example where things have gone horribly wrong. The chains never converge, nor do they mix with one another. One reason for running multiple chains is that any individual chain might converge toward one target, while another chain might converge elsewhere, and this would still be a problem. Also, you might see otherwise healthy chains get stuck on occasion over the course of the series, which might suggest more model tweaking or a change in the sampler settings is warranted.</p>
<p>We can examine the mixed chains and density plots of the posterior with standard functions in the <span class="pack">rstan</span> package displayed previously, various functions in the <span class="pack">bayesplot</span> package, or interactively via <span class="pack">shinyStan</span> package and its <span class="func">launch_shiny</span> function. In the Bayesian approach, increasing amounts of data leads to a posterior distribution of the parameter vector approaching multivariate normality. The following shows a density, trace and autocorrelation plots for one of the regression coefficients using <span class="pack">shinyStan</span>.</p>
<p><br>
<img  src="img/shiny_stan.png" style="display:block; margin: 0 auto;"></p>
</div>
<div id="statistical-measures" class="section level3" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Statistical Measures</h3>
<p>To go along with visual inspection, we can examine various statistics that might help our determination of convergence or lack thereof. Gelman and Rubin’s <em>potential scale reduction factor</em>, <span class="math inline">\(\hat{R}\)</span>, provides an estimate of convergence based on the variance of an estimated parameter <span class="math inline">\(\theta\)</span> between chains, and the variance within a chain. It is interpreted as the factor by which the variance in the estimate might be reduced with longer chains. We are looking for a value near 1 (and at the very least less than 1.1), and it will get there as <span class="math inline">\(N_{sim} \rightarrow \infty\)</span>. In the regression model things are looking good in this respect.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:center;">
estimate
</th>
<th style="text-align:center;">
rhat
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
beta[1]
</td>
<td style="text-align:center;">
4.889
</td>
<td style="text-align:center;">
1.000
</td>
</tr>
<tr>
<td style="text-align:left;">
beta[2]
</td>
<td style="text-align:center;">
0.083
</td>
<td style="text-align:center;">
1.006
</td>
</tr>
<tr>
<td style="text-align:left;">
beta[3]
</td>
<td style="text-align:center;">
-1.475
</td>
<td style="text-align:center;">
0.999
</td>
</tr>
<tr>
<td style="text-align:left;">
beta[4]
</td>
<td style="text-align:center;">
0.816
</td>
<td style="text-align:center;">
0.999
</td>
</tr>
<tr>
<td style="text-align:left;">
sigma
</td>
<td style="text-align:center;">
2.029
</td>
<td style="text-align:center;">
0.998
</td>
</tr>
</tbody>
</table>
<p>The <span class="pack">coda</span> package provides other convergence statistics based on Geweke (1992) and Heidelberger and Welch (1983). Along with those statistics, it also has plots for the <span class="math inline">\(\hat{R}\)</span> and Geweke diagnostics.</p>
</div>
<div id="autocorrelation" class="section level3" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Autocorrelation</h3>
<p>As noted previously, each estimate in the MCMC process is serially correlated with the previous estimates by definition. Furthermore, other aspects of the data, model, and estimation settings may contribute to this. Higher serial correlation typically has the effect of requiring more samples in order to get to a stationary distribution. If inspection of the traceplots look more ‘snake-like’ than like a fat hairy caterpillar, this might suggest such a situation, and that more samples are required.</p>
<p>We can also look at the autocorrelation plot, in which the chain’s correlation with successive lags of the chain are plotted. The first plot is the autocorrelation plot from our model (starting at lag 1). The correlation is low to begin with and then just bounces around zero after. The next plot shows a case of high serial correlation, where the correlation with the first lag is high and the correlation persists even after longer lags. A longer chain with more thinning could help with this.</p>
<!-- <img src="img/acfPlotNoSerial.svg" style="display:block; margin: 0 auto;" width=50%> -->
<!-- <img src="img/acfPlotSerial.svg" style="display:block; margin: 0 auto;" width=50%> -->
<p><img src="Bayesian-Basics_files/figure-html/autocorrExample-1.svg" width="500px" style="display: block; margin: auto;" /><img src="Bayesian-Basics_files/figure-html/autocorrExample-2.svg" width="500px" style="display: block; margin: auto;" /></p>
<p>The effective number of simulation draws is provided as <span class="math inline">\(n_{\textrm{eff}}\)</span> in the Stan output, and is similarly obtained in BUGS/JAGS. Ideally, we would desire this number to equal the number of posterior draws requested, and in the presence of essentially no autocorrelation the values would be equal. This is not a requirement though, and technically a low number of draws would still be usable. However, a notable discrepancy might suggest there are some issues with the model, or simply that longer chains could be useful. In our current model, all our effective sample sizes are at or near the total number of posterior draws.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:center;">
estimate
</th>
<th style="text-align:center;">
ess
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
beta[1]
</td>
<td style="text-align:center;">
4.889
</td>
<td style="text-align:center;">
1142
</td>
</tr>
<tr>
<td style="text-align:left;">
beta[2]
</td>
<td style="text-align:center;">
0.083
</td>
<td style="text-align:center;">
912
</td>
</tr>
<tr>
<td style="text-align:left;">
beta[3]
</td>
<td style="text-align:center;">
-1.475
</td>
<td style="text-align:center;">
910
</td>
</tr>
<tr>
<td style="text-align:left;">
beta[4]
</td>
<td style="text-align:center;">
0.816
</td>
<td style="text-align:center;">
988
</td>
</tr>
<tr>
<td style="text-align:left;">
sigma
</td>
<td style="text-align:center;">
2.029
</td>
<td style="text-align:center;">
844
</td>
</tr>
</tbody>
</table>
<p><em>Monte Carlo error</em> is an estimate of the uncertainty contributed by only having a finite number of posterior draws. We’d typically want roughly less than 5% of the posterior standard deviation (reported right next to it in the Stan output), but might as well go for less than 1%. With no autocorrelation it would equal <span class="math inline">\(\sqrt{\frac{var(\theta)}{n_{\textrm{eff}}}}\)</span><a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a>. and <span class="math inline">\(n_{\textrm{eff}}\)</span> would equal the number of simulation draws requested.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
mean
</th>
<th style="text-align:center;">
se_mean
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
beta[1]
</td>
<td style="text-align:left;">
4.891
</td>
<td style="text-align:center;">
0.004
</td>
</tr>
<tr>
<td style="text-align:left;">
beta[2]
</td>
<td style="text-align:left;">
0.083
</td>
<td style="text-align:center;">
0.004
</td>
</tr>
<tr>
<td style="text-align:left;">
beta[3]
</td>
<td style="text-align:left;">
-1.473
</td>
<td style="text-align:center;">
0.004
</td>
</tr>
<tr>
<td style="text-align:left;">
beta[4]
</td>
<td style="text-align:left;">
0.819
</td>
<td style="text-align:center;">
0.004
</td>
</tr>
<tr>
<td style="text-align:left;">
sigma
</td>
<td style="text-align:left;">
2.033
</td>
<td style="text-align:center;">
0.003
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="model-criticism" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Model Criticism</h2>
<p>Checking the model for suitability is crucial to the analytical process<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a>. Assuming initial diagnostic inspection for convergence has proven satisfactory, we must then see if the model makes sense in its own right. This can be a straightforward process in many respects, and with Bayesian analysis one has a much richer environment in which to do so compared to traditional methods.</p>
<div id="sensitivity-analysis" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Sensitivity Analysis</h3>
<p>Sensitivity analysis entails checks on our model settings to see if changes in them, perhaps even slight ones, result in changes in posterior inferences. This may take the form of comparing models with plausible but different priors, different sampling distributions, or differences in other aspects of the model such as the inclusion or exclusion of explanatory variables. While an exhaustive check is impossible, at least some effort in this area should be made.</p>
</div>
<div id="predictive-accuracy-model-comparison" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Predictive Accuracy &amp; Model Comparison</h3>
<p>A standard way to check for model adequacy is simply to investigate whether the predictions on new data are accurate. In general, the measure of predictive accuracy will be specific to the data problem, and involve posterior simulation of the sort covered in the next section. In addition, while oftentimes new data is hard to come by, assuming one has sufficient data to begin with, one could set aside part of it specifically for this purpose. In this manner one trains and tests the model in much the same fashion as machine learning approaches. In fact, one can incorporate the validation process as an inherent part of the modeling process in the Bayesian context just as you would there.</p>
<p>For model comparison of out of sample predictive performance, there are information measures similar to the Akaike information criterion (AIC), that one could use in the Bayesian environment. One not to use is the so-called Bayesian information criterion (or BIC), which is not actually Bayesian nor a measure of predictive accuracy. Some approaches favor the DIC, or <em>deviance information criterion</em>, as part of its summary output, which is a somewhat Bayesian version of the AIC. More recently developed are measures like <em>LOO</em> (leave-one-out criterion) and the <em>WAIC</em>, or Watanabe-AIC<a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a>, which are fully Bayesian approaches. Under some conditions, the DIC and WAIC measures are asymptotically equivalent to Bayesian leave-one-out cross validation, as the AIC is under the classical setting.</p>
</div>
<div id="posterior-predictive-checking-statistical" class="section level3" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Posterior Predictive Checking: Statistical</h3>
<p>For an overall assessment of model fit, we can examine how well the model can reproduce the data at hand given the <span class="math inline">\(\theta\)</span> draws from the posterior. We discussed earlier the <em>posterior predictive distribution</em> for a future observation <span class="math inline">\(\tilde{y}\)</span><a href="#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a>, and here we’ll dive in to using it explicitly. There are two sources of uncertainty in our regression model, the variance in <span class="math inline">\(y\)</span> not explained by the model (<span class="math inline">\(\sigma^2\)</span>), and posterior uncertainty in the parameters due to having a finite sample size. As <span class="math inline">\(N\rightarrow\infty\)</span>, the latter goes to zero, and so we can simulate draws of <span class="math inline">\(\tilde{y} \sim N(\tilde{X}\beta, \sigma^2I)\)</span><a href="#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a>. If <span class="math inline">\(\tilde{X}\)</span> is the model data as in the following, then we will refer to <span class="math inline">\(y^{\textrm{Rep}}\)</span> instead of <span class="math inline">\(\tilde{y}\)</span>.</p>
<p>For our model, this entails extracting the simulated values from the model object, and taking a random draw from the normal distribution based on the <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma\)</span> that are drawn to produce our <em>replicated data</em>, <span class="math inline">\(y^{\textrm{Rep}}\)</span> (see <span class="citation"><a href="references.html#ref-gelman_bda" role="doc-biblioref">Gelman et al.</a> (<a href="references.html#ref-gelman_bda" role="doc-biblioref">2013</a>)</span>, Appendix C). In what follows, I write out the process explicitly, but <span class="pack">bayesplot</span>, <span class="pack">rstanarm</span>, and <span class="pack">brms</span> make this straightforward, possibly with a single line of code, the latter packages using <span class="pack">bayesplot</span>. In addition, it’s often simpler to create the <span class="math inline">\(y^{\textrm{Rep}}\)</span> as part of your generated quantities section of the model code if modeling with Stan explicitly.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="model-exploration.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># extract the simulated draws from the posterior and note the number for nsims</span></span>
<span id="cb21-2"><a href="model-exploration.html#cb21-2" aria-hidden="true" tabindex="-1"></a>theta  <span class="ot">=</span> <span class="fu">extract</span>(fit)</span>
<span id="cb21-3"><a href="model-exploration.html#cb21-3" aria-hidden="true" tabindex="-1"></a>betas  <span class="ot">=</span> theta<span class="sc">$</span>beta</span>
<span id="cb21-4"><a href="model-exploration.html#cb21-4" aria-hidden="true" tabindex="-1"></a>sigmas <span class="ot">=</span> theta<span class="sc">$</span>sigma</span>
<span id="cb21-5"><a href="model-exploration.html#cb21-5" aria-hidden="true" tabindex="-1"></a>nsims  <span class="ot">=</span> <span class="fu">length</span>(theta<span class="sc">$</span>sigma)</span>
<span id="cb21-6"><a href="model-exploration.html#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="model-exploration.html#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co"># produce the replications and inspect</span></span>
<span id="cb21-8"><a href="model-exploration.html#cb21-8" aria-hidden="true" tabindex="-1"></a>yRep <span class="ot">=</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span>nsims, <span class="cf">function</span>(s) <span class="fu">rnorm</span>(<span class="dv">250</span>, X <span class="sc">%*%</span> betas[s,], sigmas[s]))</span>
<span id="cb21-9"><a href="model-exploration.html#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(yRep)</span></code></pre></div>
<pre><code> num [1:250, 1:1000] 4.44 4.47 1.12 4.3 10.04 ...</code></pre>
<p>With the <span class="math inline">\(y^{\textrm{Rep}}\)</span> in hand we can calculate all manner of statistics that might be of interest<a href="#fn38" class="footnote-ref" id="fnref38"><sup>38</sup></a>.</p>
<p>As a starting point, we can check our minimum value among the replicated data sets versus that observed in the data.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="model-exploration.html#cb23-1" aria-hidden="true" tabindex="-1"></a>min_rep <span class="ot">=</span> <span class="fu">apply</span>(yRep, <span class="dv">2</span>, min)</span>
<span id="cb23-2"><a href="model-exploration.html#cb23-2" aria-hidden="true" tabindex="-1"></a>min_y <span class="ot">=</span> <span class="fu">min</span>(y)</span>
<span id="cb23-3"><a href="model-exploration.html#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="fu">mean</span>(min_rep), min_y)</span></code></pre></div>
<pre><code>[1] -2.831253 -6.056495</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="model-exploration.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop.table</span>(<span class="fu">table</span>(min_rep <span class="sc">&gt;</span> min_y))</span></code></pre></div>
<pre><code>
FALSE  TRUE 
0.013 0.987 </code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="model-exploration.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sort</span>(y)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] -6.0564952 -3.2320527 -2.6358579 -2.1649084 -0.8366149</code></pre>
<p><img src="Bayesian-Basics_files/figure-html/posteriorPredictiveMinComparisonHist-1.svg" width="500px" style="display: block; margin: auto;" /></p>
<p>These results suggest we may be having difficulty picking up the lower tail of the target variable, as our average minimum is notably higher than that seen in the data, and almost all our minimums are greater than the observed minimum (<span class="math inline">\(p=.99\)</span>). While in this case where we are dealing with a simulated data set and we know that assuming the normal distribution for our sampling distribution is appropriate, this might otherwise have given us pause for further consideration. A possible solution would be to assume a <span class="math inline">\(t\)</span> distribution for the likelihood, which would have fatter tails and thus possibly be better able to handle extreme values. We’ll show an example of this later. In this case it is just that by chance one of the <span class="math inline">\(y\)</span> values, -6.056, is fairly extreme relative to the others. Also, it is typically difficult to capture extreme values in practice. As a comparison, the model actually captures the 5<sup>th</sup>, 10<sup>th</sup> (shown), and 25<sup>th</sup> quantile values very well.</p>
<p><img src="Bayesian-Basics_files/figure-html/posteriorPredictive10thComparisonHist-1.svg" width="500px" style="display: block; margin: auto;" /></p>
<p style="font-size:.75em; text-align:center">
See <span class="func">ppc_stat</span> in <span class="pack">bayesplot</span>.
</p>
<p>In general, we can devise a test statistic, <span class="math inline">\(T_{\textrm{Rep}}\)</span>, and associated p-value to check any particular result of interest based on the simulated data. The p-value in this context is simply the percentage of times the statistic of interest is equal to or more extreme than the statistic, <span class="math inline">\(T_y\)</span>, calculated for the original data. Thus p-values near 0 or 1 are indicative of areas where the model is falling short in some fashion. Sometimes <span class="math inline">\(T_y\)</span> may be based on the <span class="math inline">\(\theta\)</span> parameters being estimated, and thus you’d have a <span class="math inline">\(T_y\)</span> for every posterior draw. In such a case, one might examine the scatterplot of <span class="math inline">\(T_{\textrm{Rep}}\)</span> vs. <span class="math inline">\(T_y\)</span>, or examine a density plot of the difference between the two. In short, this is an area where one can get creative, and the <span class="pack">bayesplot</span> package can help with make this fairly easy. However, it must be stressed that we are not trying to accept or reject a model hypothesis as in the frequentist setting- we’re not going to throw a model out because of an extreme p-value in our posterior predictive check. We are merely trying to understand the model’s shortcomings as best we can, and make appropriate adjustments if applicable. It is often the case that the model will still be good enough for practical purposes.</p>
</div>
<div id="posterior-predictive-checking-graphical" class="section level3" number="5.2.4">
<h3><span class="header-section-number">5.2.4</span> Posterior Predictive Checking: Graphical</h3>
<p>As there are any number of ways to do statistical posterior predictive checks, we have many options for graphical inspection as well. I show a graph of our average fitted values versus the observed data as a starting point. The average is over all posterior draws of <span class="math inline">\(\theta\)</span>.</p>
<img src="Bayesian-Basics_files/figure-html/posteriorPredictiveFitted-1.svg" width="500px" style="display: block; margin: auto;" />
<p style="font-size:.75em; text-align:center">
See <span class="func">ppc_scatter_avg</span> in <span class="pack">bayesplot</span>.
</p>
<p>Next, I show density plots for a random sample of 20 of the replicated data sets along with that of the original data (shaded). It looks like we’re doing pretty well here. The subsequent figure displays the density plot for individual predictions for a single value of <span class="math inline">\(y\)</span> from our data. In general, the model captures this particular observation of the data decently.</p>
<p><img src="Bayesian-Basics_files/figure-html/posteriorPredictiveIndividually-1.svg" width="500px" style="display: block; margin: auto;" /><img src="Bayesian-Basics_files/figure-html/posteriorPredictiveIndividually-2.svg" width="500px" style="display: block; margin: auto;" /></p>
<p style="font-size:.75em; text-align:center">
See <span class="func">ppc_dens_overlay</span> in <span class="pack">bayesplot</span>.
</p>
<p>We can also examine residual plots of <span class="math inline">\(y - E(y|X,\theta)\)</span> as with standard analysis, shown as the final two figures for this section. The first shows such ‘realized’ residuals, so-called as they are based on a posterior draw of <span class="math inline">\(\theta\)</span> rather than point estimation of the parameters, versus the expected values from the model. The next plot shows the average residual against the average fitted value. No discernible patterns are present, so we may conclude that the model is adequate in this regard<a href="#fn39" class="footnote-ref" id="fnref39"><sup>39</sup></a>.</p>
<p><img src="Bayesian-Basics_files/figure-html/posteriorPredictiveResiduals-1.svg" width="500px" style="display: block; margin: auto;" /><img src="Bayesian-Basics_files/figure-html/posteriorPredictiveResiduals-2.svg" width="500px" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="summary" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Summary</h2>
<p>As with standard approaches, every model should be checked to see whether it holds up under scrutiny. The previous discussion suggests only a few ways one might go about checking whether the model is worthwhile, but this is a very flexible area where one can answer questions beyond model adequacy and well beyond what traditional models can tell us. Not only is this phase of analysis a necessity, one can use it to explore a vast array of potential questions the data presents, and maybe even answer a few.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="31">
<li id="fn31"><p>I wonder how many results have been published on models that didn’t converge with the standard MLE. People will often ignore warnings as long as they get some sort of result.<a href="model-exploration.html#fnref31" class="footnote-back">↩︎</a></p></li>
<li id="fn32"><p>Recall again that we are looking for convergence to a distribution, not a point estimate of a specific parameter.<a href="model-exploration.html#fnref32" class="footnote-back">↩︎</a></p></li>
<li id="fn33"><p>This is the ‘naive’ estimate that packages like <span class="pack">coda</span> might provide in the summary output.<a href="model-exploration.html#fnref33" class="footnote-back">↩︎</a></p></li>
<li id="fn34"><p>Gelman devotes an entire chapter to this topic to go along with examples of model checking throughout his text. Much of this section follows that outline.<a href="model-exploration.html#fnref34" class="footnote-back">↩︎</a></p></li>
<li id="fn35"><p>See <a href="http://www.stat.columbia.edu/~gelman/research/published/waic_understand3.pdf">Gelman et al. (2013)</a> for a review and references. See <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/waic_stan.pdf">Vehtari &amp; Gelman (2014)</a> for some more on WAIC, as well as the R package <span class="pack">loo</span>. In general, the Stan group prefers <em>loo</em> <span class="citation"><a href="references.html#ref-vehtari2017practical" role="doc-biblioref">Vehtari, Gelman, and Gabry</a> (<a href="references.html#ref-vehtari2017practical" role="doc-biblioref">2017</a>)</span>.<a href="model-exploration.html#fnref35" class="footnote-back">↩︎</a></p></li>
<li id="fn36"><p><span class="math inline">\(p(\tilde{y}|y) = \int p(\tilde{y}|\theta)p(\theta|y)\mathrm{d}\theta\)</span><a href="model-exploration.html#fnref36" class="footnote-back">↩︎</a></p></li>
<li id="fn37"><p>Technically, in the conjugate case the posterior predictive is t-distributed because of the uncertainty in the parameters, though it doesn’t take much sample size for simple models to get to approximately normal. Formally, with <span class="math inline">\(\hat{\beta}\)</span> being our mean <span class="math inline">\(\beta\)</span> estimate from the posterior, this can be represented as: <br> <span class="math inline">\(\tilde{y} \sim t(\tilde{X}\hat{\beta}, \sigma^2 + \textrm{parUnc}, \textrm{df}=N-k)\)</span><a href="model-exploration.html#fnref37" class="footnote-back">↩︎</a></p></li>
<li id="fn38"><p>In many cases you might want to produce this in the generated quantities section of your Stan code, but doing so outside of it will keep the <span class="objclass">stanfit</span> object smaller, which may be desirable.<a href="model-exploration.html#fnref38" class="footnote-back">↩︎</a></p></li>
<li id="fn39"><p>The two plots directly above replicate the figures in 6.11 in Gelman 2013.<a href="model-exploration.html#fnref39" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
  </main>

  <div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page">
      <h2>On this page</h2>
      <div id="book-on-this-page"></div>

      <div class="book-extra">
        <ul class="list-unstyled">
          <li><a id="book-source" href="#">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="#">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
      </div>
    </nav>
  </div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5">
  <div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Bayesian Basics</strong>" was written by <p><span class="noem">Michael Clark</span> <br>
<a href="https://m-clark.github.io/">m-clark.github.io</a></p>. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
<script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>

</html>
