<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Chapter 2 Introduction | Bayesian Basics</title>

  
   <meta name="description" content="This document provides an introduction to Bayesian data analysis. It is conceptual in nature, but uses the probabilistic programming language Stan for demonstration (and its implementation in R via rstan). From elementary examples, guidance is provided for data preparation, efficient modeling, diagnostics, and more." />
   <meta name="generator" content="placeholder" />
  <meta property="og:title" content="Chapter 2 Introduction | Bayesian Basics" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://m-clark.github.io/bayesian-basics/" />
  <meta property="og:image" content="https://m-clark.github.io/bayesian-basics//img/nineteeneightyR.png" />
  <meta property="og:description" content="This document provides an introduction to Bayesian data analysis. It is conceptual in nature, but uses the probabilistic programming language Stan for demonstration (and its implementation in R via rstan). From elementary examples, guidance is provided for data preparation, efficient modeling, diagnostics, and more." />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Introduction | Bayesian Basics" />
  
  <meta name="twitter:description" content="This document provides an introduction to Bayesian data analysis. It is conceptual in nature, but uses the probabilistic programming language Stan for demonstration (and its implementation in R via rstan). From elementary examples, guidance is provided for data preparation, efficient modeling, diagnostics, and more." />
  <meta name="twitter:image" content="https://m-clark.github.io/bayesian-basics//img/nineteeneightyR.png" />
  <!-- JS -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script>
  <script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script>
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet" />
    <script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script>
    <script src="libs/bs3compat-0.3.1/transition.js"></script>
    <script src="libs/bs3compat-0.3.1/tabs.js"></script>
    <script src="libs/bs3compat-0.3.1/bs3compat.js"></script>
    <link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet" />
    <script src="libs/bs4_book-1.0.0/bs4_book.js"></script>
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
    <script src="libs/plotly-binding-4.10.0/plotly.js"></script>
    <script src="libs/typedarray-0.1/typedarray.min.js"></script>
    <link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
    <script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
    <link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
    <script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script>

  <!-- CSS -->
  
</head>

<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book">
    <a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Bayesian Basics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
      </form>

      <nav aria-label="Table of contents">
        <h2>Table of contents</h2>
        <div id="book-toc"></div>

        <div class="book-extra">
          <p><a id="book-repo" href="#">View book source <i class="fab fa-github"></i></a></li></p>
        </div>
      </nav>
    </div>
  </header>

  <main class="col-sm-12 col-md-9 col-lg-7" id="content">
<div id="introduction" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Introduction</h1>
<p>Bayesian analysis is now fairly common in applied work. It is no longer a surprising thing to see it utilized in non-statistical journals, though it is still fresh enough that many researchers feel they have to put ‘Bayesian’ in the title of their papers when they implement it. However, to be clear, one doesn’t conduct a Bayesian analysis per se. A Bayesian logistic regression is still just logistic regression. The <em>Bayesian</em> part comes into play with the perspective on probability that one uses to interpret the results, and in how the estimates are arrived at.</p>
<p>The Bayesian approach itself is very old at this point. Bayes and Laplace started the whole shebang in the 18<sup>th</sup> and 19<sup>th</sup> centuries<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, and even the modern implementation of it has its foundations in the 30s, 40s and 50s of last century<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>. So while it may still seem somewhat newer relative to more common techniques, much of the groundwork has long since been hashed out, and there is no more need to justify a Bayesian analysis any more than there is to use the standard maximum likelihood or other approach<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>. While there are perhaps many reasons why the Bayesian approach to analysis did not catch on until relatively recently, perhaps the biggest is simply computational power. Bayesian analysis requires an iterative and time-consuming approach that simply wasn’t viable for most applied researchers until modern computing. But nowadays, one can conduct such analysis even on their laptop very easily.</p>
<p>The Bayesian approach to data analysis requires a different way of thinking about things, but its implementation can be seen as an extension of traditional approaches. In fact, as we will see later, it incorporates the very likelihood one uses in standard statistical techniques. The key difference regards the notion of probability, which, while different than Fisherian or frequentist statistics, is actually more akin to how the average Joe thinks about probability. Furthermore, p-values and intervals will have the interpretation that many applied researchers incorrectly think their current methods provide. On top of this, one gets a very flexible toolbox that can handle many complex analyses. In short, the reason to engage in Bayesian analysis is that it has a lot to offer and can potentially handle whatever you throw at it.</p>
<p>As we will see shortly, one must also get used to thinking about distributions rather than fixed points. With Bayesian analysis, we are not so much as making guesses about specific values as in the traditional setting, but more so trying to understand the limits of our knowledge and getting a healthy sense of the uncertainty of those guesses.</p>
<div id="bayesian-probability" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Bayesian Probability</h2>
<p>This section will probably be about as formal as this document gets, and will be very minimal even then. The focus still will be on the conceptual understanding though, and subsequently illustrated with a by-hand example in the next section.</p>
<div id="conditional-probability-bayes-theorem" class="section level3" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Conditional probability &amp; Bayes theorem</h3>
<p>Bayes theorem is illustrated in terms of probability as follows:</p>
<p><span class="math display">\[p(\mathcal{A}|\mathcal{B}) = \frac{p(\mathcal{B}|\mathcal{A})p(\mathcal{A})}{p(\mathcal{B})}\]</span></p>
<p>In short, we are attempting to ascertain the conditional probability of <span class="math inline">\(\mathcal{A}\)</span> given <span class="math inline">\(\mathcal{B}\)</span> based on the conditional probability of <span class="math inline">\(\mathcal{B}\)</span> given <span class="math inline">\(\mathcal{A}\)</span> and the respective probabilities of <span class="math inline">\(\mathcal{A}\)</span> and <span class="math inline">\(\mathcal{B}\)</span>. This is perhaps not altogether enlightening in and of itself, so we will frame it in other ways, and for the upcoming depictions we will ignore the denominator<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>.</p>
<p><span class="math display">\[p(hypothesis|data) \propto p(data|hypothesis)p(hypothesis)\]</span></p>
<p>In the above formulation<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>, we are trying to obtain the probability of a hypothesis given the evidence at hand (data) and our initial (prior) beliefs regarding that hypothesis. Here we are already able to see at least one key difference between Bayesian and classical statistics. The Bayesian approach provides a probability of the hypothesis given the data, which is something very desirable from a scientific perspective.</p>
<p>Here is yet another way to consider this:</p>
<p><span class="math display">\[posterior \propto likelihood * prior\]</span></p>
<p>For this depiction, let us consider a standard regression coefficient <span class="math inline">\(b\)</span><a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>. Here we have a prior belief about <span class="math inline">\(b\)</span> expressed as a probability distribution. As a preliminary example, we will assume that perhaps the distribution is normal, and is centered on some value <span class="math inline">\(\mu_b\)</span>, and with some variance <span class="math inline">\(\sigma_b^2\)</span>. The likelihood here is the exact same one used in classical statistics- if <span class="math inline">\(y\)</span> is our variable of interest, then the likelihood is <span class="math inline">\(p(y|b)\)</span> as in the standard regression approach using maximum likelihood estimation. What we end up with in the Bayesian context however is not a specific value of <span class="math inline">\(b\)</span> that would make the data most likely, but a probability distribution for <span class="math inline">\(b\)</span> that serves as a weighted combination of the likelihood and prior. Given that <em>posterior distribution</em> for <span class="math inline">\(b\)</span>, we can then get the mean, median, 95% <em>credible interval</em><a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>, and a whole host of other statistics that might be of interest to us.</p>
<p>To summarize conceptually, we have some belief about the state of the world, expressed as a mathematical model (such as the linear model used in regression). The Bayesian approach provides an updated belief as a weighted combination of prior beliefs regarding that state, and the currently available evidence. In addition, there is the possibility of the current evidence overwhelming prior beliefs, or prior beliefs remaining largely intact in the face of scant evidence.</p>
<p><span class="math display">\[\text{updated belief} = \text{current evidence} * \text{prior belief or evidence}\]</span></p>
<p>We will make these concepts more concrete in the next section.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Bayes theorem possibly <a href="https://en.wikipedia.org/wiki/Nicholas_Saunderson">predates</a> Bayes himself by some accounts.<a href="introduction.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Jeffreys, Metropolis etc.<a href="introduction.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Though some might suggest that the typical practice of hypothesis testing that comes with standard methods would need <em>more</em>.<a href="introduction.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>The denominator reflects the sum of the numerator for <em>all</em> values <span class="math inline">\(\mathcal{A}\)</span> might take on. For example:
<span class="math display">\[p(\mathcal{A_i}|\mathcal{B}) = \frac{p(\mathcal{B}|\mathcal{A_i})p(\mathcal{A_i})}{p(\mathcal{B}|\mathcal{A_i})p(\mathcal{A_i}) + \dots + p(\mathcal{B}|\mathcal{A_n})p(\mathcal{A_n})}\]</span><a href="introduction.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>The <span class="math inline">\(\propto\)</span> means ‘proportional to.’<a href="introduction.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>If we think of y as our outcome and <span class="math inline">\(\Theta\)</span> as our <em>set</em> of coefficients that include all the regression coefficients <span class="math inline">\(b\)</span> and <span class="math inline">\(\sigma^2\)</span> variance, i.e. all parameters we need to estimate for the model: <span class="math display">\[p(\mathcal{\Theta}|\mathcal{y}) = \frac{p(\mathcal{y}|\mathcal{\Theta})p(\mathcal{\Theta})}{p(\mathcal{y})}\]</span><a href="introduction.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>More on this later.<a href="introduction.html#fnref7" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
  </main>

  <div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page">
      <h2>On this page</h2>
      <div id="book-on-this-page"></div>

      <div class="book-extra">
        <ul class="list-unstyled">
          <li><a id="book-source" href="#">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="#">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
      </div>
    </nav>
  </div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5">
  <div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Bayesian Basics</strong>" was written by <p><span class="noem">Michael Clark</span> <br>
<a href="https://m-clark.github.io/">m-clark.github.io</a></p>. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
<script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>

</html>
